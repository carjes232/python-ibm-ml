{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Understand the core components of a Transformer architecture.\n",
    "- Implement a multi-head self-attention mechanism from scratch.\n",
    "- Train and evaluate a Transformer for time series prediction.\n",
    "- Handle preprocessing and scaling for time series data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Transformer?\n",
    "\n",
    "The Transformer architecture was introduced in the paper *\"Attention Is All You Need\"*. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
    "\n",
    "### Key Components:\n",
    "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
    "- **Positional Encoding:** Injects information about the position of input tokens.\n",
    "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
    "- **Feedforward Layers:** Process the attended information.\n",
    "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
    "\n",
    "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
    "\n",
    "**Next:** You will implement parts of this architecture step-by-step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, pyarrow, protobuf, pillow, optree, opt_einsum, numpy, mdurl, markdown, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, ml_dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 h5py-3.14.0 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 numpy-2.3.3 opt_einsum-3.4.0 optree-0.17.0 pillow-11.3.0 protobuf-6.32.1 pyarrow-21.0.0 rich-14.1.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m185.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.3.3 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.3.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m137.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m151.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.6 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 21:32:24.509302: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-02 21:32:24.509869: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-02 21:32:24.580817: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-02 21:32:26.905194: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-02 21:32:26.905853: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 22:27:33.954036: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1059 \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1395 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1742 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1262\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0802 \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 0.0774 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - loss: 0.0810 \n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - loss: 0.0704\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3s/step - loss: 0.0710\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - loss: 0.0651\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - loss: 0.0655\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - loss: 0.0714\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - loss: 0.0705\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - loss: 0.0492\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - loss: 0.0356\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - loss: 0.0403\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3s/step - loss: 0.0313\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - loss: 0.0409\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - loss: 0.0188\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3s/step - loss: 0.0194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x714286ccd010>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAkxVJREFUeJzs3XdYU9cbwPFvEiBsEBUQxb33rGKdFfceddZdtVZr1VqrbbXaZavWUX9VO13VOlr33uKuu3XhAje4GCICIbm/PyiByJCRsHw/z8Mj99xzzzk3QfJy7hkqRVEUhBBCCCHyKHV2N0AIIYQQwpIk2BFCCCFEnibBjhBCCCHyNAl2hBBCCJGnSbAjhBBCiDxNgh0hhBBC5GkS7AghhBAiT5NgRwghhBB5mgQ7QgghhMjTJNgROVLx4sUZMGCA8Xj//v2oVCr2799vtjpUKhVTpkwxW3lCAEyfPp3y5ctjMBiypf7AwEBUKhUzZ87MlvozasqUKahUKrOW2aRJE5o0aWLWMs1p8eLFqFQqTp48mWq+CRMmULdu3SxqVd4kwY5IIv4/YPyXra0tZcuWZeTIkQQHB2d389Jl69atEtAkEv+B8rKv7P6AiA9u47+0Wi0eHh40adKEr7/+mocPH2a47IsXLzJlyhQCAwPN1+D/hIeH8+233/LRRx+hVif8en3x9XVwcKBixYp8+eWXREZGZqguS/5sBwYGMnDgQEqVKoWtrS2enp40atSIzz77zCL1ZbfixYsn+Z1XpkwZPvzwQ548eZLdzWP06NGcO3eOjRs3ZndTci2r7G6AyLk+//xzSpQoQVRUFIcOHWLBggVs3bqV8+fPY29vn6VtadSoEc+fP8fGxiZd123dupUffvgh2Q+F58+fY2X1av0X6NKlC6VLlzYeR0REMHz4cDp37kyXLl2M6R4eHtnRvCRGjRpFnTp10Ov1PHz4kCNHjvDZZ58xa9YsVq9ezRtvvJHuMi9evMjUqVNp0qQJxYsXN2t7f/vtN2JjY+nVq1eSc82bN6dfv35A3Ot+8OBBJk2axLlz51izZk2660rtZzszrl27Rp06dbCzs2PQoEEUL16c+/fvc/r0ab799lumTp1q1vpyiurVq/PBBx8AEBUVxalTp5gzZw4HDhzg77//zta2eXp60rFjR2bOnEmHDh2ytS251av1m16kS+vWralduzYAb7/9Nvnz52fWrFls2LAh2V/mAM+ePcPBwcHsbVGr1dja2pq1THOXlxtUrVqVqlWrGo8fPXrE8OHDqVq1Km+99VaK10VFRWFjY2PSW5EVGjZsSLdu3UzSzp07R4sWLejatSsXL16kUKFCWdqm1CxatIgOHTok+7NVtmxZk9f4nXfeISYmhrVr1xIVFZVjfh5nz55NREQEZ8+epVixYibnHjx4kE2tsrzChQubvD9vv/02jo6OzJw5k6tXr1KmTJlsbB10796dN998kxs3blCyZMlsbUtuJI+xRJrF/xUdEBAAwIABA3B0dOT69eu0adMGJycn+vTpA4DBYGDOnDlUqlQJW1tbPDw8GDZsGCEhISZlKorCl19+SZEiRbC3t6dp06ZcuHAhSd0pjdk5fvw4bdq0IV++fDg4OFC1alXmzp1rbN8PP/wAmD5GiJfcmJ0zZ87QunVrnJ2dcXR0pFmzZhw7dswkT/xjvsOHDzN27FgKFiyIg4MDnTt3TvJ45eTJk7Rs2ZICBQpgZ2dHiRIlGDRoUKqvc7t27VL8Zebj42MMQAF27dpFgwYNcHV1xdHRkXLlyvHxxx+nWv7LxL/WK1eu5NNPP6Vw4cLY29sTHh6e4riK+NfkxUdD27Zto2HDhjg4OODk5ETbtm2TfX/To1q1asyZM4fQ0FD+97//GdNv3rzJu+++S7ly5bCzsyN//vy8+eabJm1avHgxb775JgBNmzY1/kzE/1xt2LCBtm3b4uXlhVarpVSpUnzxxRfo9fqXtisgIIB//vkHX1/fNN+Lp6cnKpUqSQ/jmjVrqFWrFnZ2dhQoUIC33nqLu3fvGs+/7Gc73k8//USpUqXQarXUqVOHEydOvLRN169fp0iRIkkCHQB3d/ckadu2baNx48Y4OTnh7OxMnTp1WLFihfH8wYMHefPNNylatCharRZvb2/GjBnD8+fPX9oWgN9//934Wri5udGzZ09u376d4r3a2dnx2muvcfDgwTSVnxpPT08Ak/fnn3/+YcCAAZQsWdL4iG/QoEE8fvw4yfV3795l8ODBxp+nEiVKMHz4cGJiYlKsMyQkhNdee40iRYrg7+9vTI//udqwYUOm7+tVJD07Is2uX78OQP78+Y1psbGxtGzZkgYNGjBz5kzj461hw4axePFiBg4cyKhRowgICOB///sfZ86c4fDhw1hbWwMwefJkvvzyS9q0aUObNm04ffo0LVq0SPWXQbxdu3bRrl07ChUqxPvvv4+npyeXLl1i8+bNvP/++wwbNox79+6xa9culi1b9tLyLly4QMOGDXF2dmb8+PFYW1vz448/0qRJEw4cOJBkgOB7771Hvnz5+OyzzwgMDGTOnDmMHDmSVatWAXF/Bbdo0YKCBQsyYcIEXF1dCQwMZO3atam2o0ePHvTr148TJ05Qp04dY/rNmzc5duwYM2bMMLa3Xbt2VK1alc8//xytVsu1a9c4fPjwS+81Lb744gtsbGwYN24c0dHR6X6EuGzZMvr370/Lli359ttviYyMZMGCBTRo0IAzZ85k6hFSt27dGDx4MDt37uSrr74C4MSJExw5coSePXtSpEgRAgMDWbBgAU2aNOHixYvY29vTqFEjRo0axffff8/HH39MhQoVAIz/Ll68GEdHR8aOHYujoyN79+5l8uTJhIeHG1/3lBw5cgSAmjVrJns+KiqKR48eAXE9oIcPH2bJkiX07t3b5MM0/v9NnTp1mDZtGsHBwcydO5fDhw9z5swZXF1d0/SzvWLFCp4+fcqwYcNQqVRMnz6dLl26cOPGDeP/v+QUK1aM3bt3s3fv3pc+Jly8eDGDBg2iUqVKTJw4EVdXV86cOcP27dvp3bs3EBe4RUZGMnz4cPLnz8/ff//NvHnzuHPnzksf33311VdMmjSJ7t278/bbb/Pw4UPmzZtHo0aNjK8FwK+//sqwYcOoX78+o0eP5saNG3To0AE3Nze8vb1TrSOeTqczvj9RUVGcOXOGWbNm0ahRI0qUKGHMt2vXLm7cuMHAgQPx9PTkwoUL/PTTT1y4cIFjx44Zg8579+7x2muvERoaytChQylfvjx3797lzz//JDIyMtn/T48ePaJ58+Y8efKEAwcOUKpUKeM5FxcXSpUqxeHDhxkzZkya7kkkogjxgkWLFimAsnv3buXhw4fK7du3lZUrVyr58+dX7OzslDt37iiKoij9+/dXAGXChAkm1x88eFABlOXLl5ukb9++3ST9wYMHio2NjdK2bVvFYDAY83388ccKoPTv39+Ytm/fPgVQ9u3bpyiKosTGxiolSpRQihUrpoSEhJjUk7isESNGKCn9mAPKZ599Zjzu1KmTYmNjo1y/ft2Ydu/ePcXJyUlp1KhRktfH19fXpK4xY8YoGo1GCQ0NVRRFUdatW6cAyokTJ5KtPyVhYWGKVqtVPvjgA5P06dOnKyqVSrl586aiKIoye/ZsBVAePnyYrvITe/jwYZLXIf61LlmypBIZGWmS/7PPPkv29Yx/TQICAhRFUZSnT58qrq6uypAhQ0zyBQUFKS4uLknSXxTfhjVr1qSYp1q1akq+fPmMxy+2VVEU5ejRowqgLF261Ji2Zs0ak5+lxJIrY9iwYYq9vb0SFRWVaps//fRTBVCePn2a5ByQ7FenTp1Myo2JiVHc3d2VypUrK8+fPzemb968WQGUyZMnG9NS+tkOCAhQACV//vzKkydPjOkbNmxQAGXTpk2p3sf58+cVOzs7BVCqV6+uvP/++8r69euVZ8+emeQLDQ1VnJyclLp165q0VVFM/w8m95pOmzbN5GdZUZL+bAUGBioajUb56quvTK79999/FSsrK2N6/GtWvXp1JTo62pjvp59+UgClcePGqd6voihKsWLFkn1/Xn/9deXRo0cmeZO7nz/++EMBFD8/P2Nav379FLVanez///jXJ/7/zYkTJ5T79+8rlSpVUkqWLKkEBgYm284WLVooFSpUeOn9iKTkMZZIka+vLwULFsTb25uePXvi6OjIunXrKFy4sEm+4cOHmxyvWbMGFxcXmjdvzqNHj4xftWrVwtHRkX379gGwe/duYmJieO+990y64EePHv3Stp05c4aAgABGjx5t/OsuXkamr+r1enbu3EmnTp1MHiEVKlSI3r17c+jQIcLDw02uGTp0qEldDRs2RK/Xc/PmTQBjuzZv3oxOp0tzW5ydnWndujWrV69GURRj+qpVq6hXrx5FixY1KX/Dhg0Wmebcv39/7OzsMnTtrl27CA0NpVevXiY/AxqNhrp16xp/BjLD0dGRp0+fGo8Tt1Wn0/H48WNKly6Nq6srp0+fTlOZict4+vQpjx49omHDhkRGRnL58uVUr338+DFWVlY4Ojome75jx47s2rWLXbt2sWHDBiZOnGjsAYl/n0+ePMmDBw949913TcbwtG3blvLly7Nly5Y03QfE9RDmy5fPeNywYUMAbty4kep1lSpV4uzZs7z11lsEBgYyd+5cOnXqhIeHBz///LMx365du3j69CkTJkxIMt4o8f+LxK/ps2fPePToEfXr10dRFM6cOZNiO9auXYvBYKB79+4mP0Oenp6UKVPG+DMU/5q98847Jr0lAwYMwMXFJdV7Taxu3brG92fz5s189dVXXLhwgQ4dOpg8ckt8P/G9dfXq1QMw/pwZDAbWr19P+/btTR47J/f6ANy5c4fGjRuj0+nw8/NL9hEiQL58+Yy9TyJ95DGWSNEPP/xA2bJlsbKywsPDg3LlyiUZoGplZUWRIkVM0q5evUpYWFiyz/chYZBjfFDw4sC/ggULmvySTk78I7XKlSun/YZS8fDhQyIjIylXrlyScxUqVMBgMHD79m0qVapkTI8POuLFtzl+XFLjxo3p2rUrU6dOZfbs2TRp0oROnTrRu3dvtFptqu3p0aMH69ev5+jRo9SvX5/r168bZ4ckzvPLL7/w9ttvM2HCBJo1a0aXLl3o1q2bWQYSJ+66T6+rV68CpPgYxNnZOcNlx4uIiMDJycl4/Pz5c6ZNm8aiRYu4e/euSaAYFhaWpjIvXLjAp59+yt69e5MEt2ktIyVFihQxGc/ToUMH8ufPz7hx49i8eTPt27c3/p9I7uewfPnyHDp0KM31veznMzVly5Zl2bJl6PV6Ll68yObNm5k+fTpDhw6lRIkS+Pr6pvn/4K1bt5g8eTIbN25MUndqr+nVq1dRFCXFgcHxj+JS+j1ibW2droG8BQoUMHl/2rZtS7ly5ejWrRu//PIL7733HgBPnjxh6tSprFy5MsmA7fj7efjwIeHh4Wn+/dS3b1+srKy4dOmScZxQchRFMftaRK8KCXZEil577bVk/ypJTKvVJvlgNRgMuLu7s3z58mSvKViwoNnamJ00Gk2y6fEfsiqVij///JNjx46xadMmduzYwaBBg/juu+84duxYij0AAO3bt8fe3p7Vq1dTv359Vq9ejVqtNg6uhbi/MP38/Ni3bx9btmxh+/btrFq1ijfeeIOdO3em2L60Sq5XJ6VftC8O4I3vaVq2bFmyv7wzO+Vfp9Nx5coVkw+T9957j0WLFjF69Gh8fHxwcXFBpVLRs2fPNPV8hYaG0rhxY5ydnfn888+Na8ycPn2ajz766KVl5M+fn9jYWJ4+fWoShKWmWbNmAPj5+dG+ffs0XZNWL/v5TGsZVapUoUqVKvj4+NC0aVOWL1+e5kHYer3eOAblo48+onz58jg4OHD37l0GDBiQ6mtqMBhQqVRs27Yt2XtJ7f+PuSR+f+KDne7du3PkyBE+/PBDqlevjqOjIwaDgVatWmW4h7VLly4sXbqUuXPnMm3atBTzhYSEUKBAgQzV8aqTYEeYXalSpdi9ezevv/56qo9B4rtqr169avIX2MOHD1/612f8wL3z58+n+os3rX8FFSxYEHt7e5PZD/EuX76MWq1O80DHF9WrV4969erx1VdfsWLFCvr06cPKlSt5++23U7zGwcGBdu3asWbNGmbNmsWqVato2LAhXl5eJvnUajXNmjWjWbNmzJo1i6+//ppPPvmEffv2pWtWUFrF9w6EhoaaPD6M/+s6Xvz74+7ubpF2/Pnnnzx//pyWLVuapPXv35/vvvvOmBYVFUVoaKjJtSn9TOzfv5/Hjx+zdu1aGjVqZEyPn334MuXLlzfmTzy9PzWxsbFAXC8VJPyf8Pf3T9Ir5u/vb/J4I6v/wo//w+f+/fuA6f/BxGs3Jfbvv/9y5coVlixZYlxjCOIegb1MqVKlUBSFEiVKULZs2RTzJf49kvg10+l0BAQEUK1atZfWlZIX35+QkBD27NnD1KlTmTx5sjFffE9mvIIFC+Ls7Mz58+fTVM97771H6dKlmTx5Mi4uLkyYMCHZfJm9n1eZjNkRZte9e3f0ej1ffPFFknOxsbHGDx9fX1+sra2ZN2+eyV+biR/VpKRmzZqUKFHCOAU5scRlxa/582KeF2k0Glq0aMGGDRtMpioHBwezYsUKGjRokO5HLyEhIUn+iq5evToA0dHRL72+R48e3Lt3j19++YVz587Ro0cPk/PJreyanvIzIv4Dzs/Pz5j27NkzlixZYpKvZcuWODs78/XXXyc7XikzKyCfO3eO0aNHky9fPkaMGGFM12g0SV7vefPmJel1SulnIr73IHEZMTExzJ8/P03t8vHxAXjp0v+Jbdq0CcD4AVa7dm3c3d1ZuHChyXu4bds2Ll26RNu2bV96H5l18ODBZN+zrVu3AgmP2Fq0aIGTkxPTpk0jKirKJG/8a5jca6ooinF5iNR06dIFjUbD1KlTk7yviqIYp3rXrl2bggULsnDhQpNZnIsXL870a/Pi+5Pc/UDS31lqtZpOnTqxadOmZH8ekutdmzRpEuPGjWPixIksWLAgyfmwsDCuX79O/fr1M3Qvrzrp2RFm17hxY4YNG8a0adM4e/YsLVq0wNramqtXr7JmzRrmzp1Lt27dKFiwIOPGjWPatGm0a9eONm3acObMGbZt2/bSrlq1Ws2CBQto37491atXZ+DAgRQqVIjLly9z4cIFduzYAUCtWrWAuJV4W7ZsiUajoWfPnsmW+eWXXxrXrXn33XexsrLixx9/JDo6munTp6f7dViyZAnz58+nc+fOlCpViqdPn/Lzzz/j7OxMmzZtXnp9/NpF48aNQ6PR0LVrV5Pzn3/+OX5+frRt25ZixYrx4MED5s+fT5EiRWjQoEG625sWLVq0oGjRogwePJgPP/wQjUbDb7/9RsGCBbl165Yxn7OzMwsWLKBv377UrFmTnj17GvNs2bKF119/3WSNnJQcPHiQqKgo9Ho9jx8/5vDhw2zcuBEXFxfWrVtn8oisXbt2LFu2DBcXFypWrMjRo0fZvXu3yVIJEBcQajQavv32W8LCwtBqtbzxxhvUr1+ffPny0b9/f0aNGoVKpWLZsmVpfuxTsmRJKleuzO7du5NdS+nKlSv8/vvvAERGRnLs2DGWLFlC6dKl6du3LxA3zuTbb79l4MCBNG7cmF69ehmnnhcvXtxkynF6frbT49tvv+XUqVN06dLF2EN1+vRpli5dipubm3ECgbOzM7Nnz+btt9+mTp069O7dm3z58nHu3DkiIyNZsmQJ5cuXp1SpUowbN467d+/i7OzMX3/9laZxQ6VKleLLL79k4sSJBAYG0qlTJ5ycnAgICGDdunUMHTqUcePGYW1tzZdffsmwYcN444036NGjBwEBASxatChdY3bu3r1rfH9iYmI4d+4cP/74IwUKFDA+wnJ2dqZRo0ZMnz4dnU5H4cKF2blzZ7K9f19//TU7d+6kcePGDB06lAoVKnD//n3WrFnDoUOHkkysAJgxYwZhYWGMGDECJycnk0UOd+/ejaIodOzYMc33JBLJwplfIpdIPB0yNf3791ccHBxSPP/TTz8ptWrVUuzs7BQnJyelSpUqyvjx45V79+4Z8+j1emXq1KlKoUKFFDs7O6VJkybK+fPnlWLFiqU69TzeoUOHlObNmytOTk6Kg4ODUrVqVWXevHnG87Gxscp7772nFCxYUFGpVCZTW3lhyrWiKMrp06eVli1bKo6Ojoq9vb3StGlT5ciRI2l6fV5s4+nTp5VevXopRYsWVbRareLu7q60a9dOOXnyZGovq4k+ffoYp7m/aM+ePUrHjh0VLy8vxcbGRvHy8lJ69eqlXLlyJc3lpzb1PKVp36dOnVLq1q2r2NjYKEWLFlVmzZqVZOp54rJatmypuLi4KLa2tkqpUqWUAQMGvPQ1iG9D/Je1tbVSsGBBpVGjRspXX32lPHjwIMk1ISEhysCBA5UCBQoojo6OSsuWLZXLly8n+VlSFEX5+eeflZIlSyoajcbkPTt8+LBSr149xc7OTvHy8lLGjx+v7NixI8Wp6i+aNWuW4ujomGR6cuJ7ARSNRqMUKVJEGTp0qBIcHJyknFWrVik1atRQtFqt4ubmpvTp08e45EO8lH6246eez5gxI0m5yf3Mv+jw4cPKiBEjlMqVKysuLi6KtbW1UrRoUWXAgAEmyzLE27hxo1K/fn3Fzs5OcXZ2Vl577TXljz/+MJ6/ePGi4uvrqzg6OioFChRQhgwZopw7d04BlEWLFhnzpbSswV9//aU0aNBAcXBwUBwcHJTy5csrI0aMUPz9/U3yzZ8/XylRooSi1WqV2rVrK35+fkrjxo0zNPVcrVYr7u7uSq9evZRr166Z5L1z547SuXNnxdXVVXFxcVHefPNN5d69e8m+tjdv3lT69eunFCxYUNFqtUrJkiWVESNGGKfIJ/e7RK/XK7169VKsrKyU9evXG9N79OihNGjQ4KX3IpKnUpR0jFYTQgiRorCwMEqWLMn06dMZPHhwdjdH5BFBQUGUKFGClStXSs9OBsmYHSGEMBMXFxfGjx/PjBkzLLL2kXg1zZkzhypVqkigkwnSsyOEEEKIPE16doQQQgiRp0mwI4QQQog8TYIdIYQQQuRpEuwIIYQQIk+TRQWJ24Pl3r17ODk5ySZrQgghRC6hKApPnz7Fy8sr1Q2QJdgB7t27l+F9j4QQQgiRvW7fvk2RIkVSPC/BDhh3KL59+3a69z8SQgghRPYIDw/H29vb+DmeEgl2SNg92NnZWYIdIYQQIpd52RAUGaAshBBCiDxNgh0hhBBC5GkS7AghhBAiT5MxO+mg1+vR6XTZ3QxhYdbW1mg0muxuhhBCCDORYCcNFEUhKCiI0NDQ7G6KyCKurq54enrKuktCCJEHSLCTBvGBjru7O/b29vIBmIcpikJkZCQPHjwAoFChQtncIiGEEJklwc5L6PV6Y6CTP3/+7G6OyAJ2dnYAPHjwAHd3d3mkJYQQuZwMUH6J+DE69vb22dwSkZXi328ZoyWEELmfBDtpJI+uXi3yfgshRN4hwY4QQggh8jQJdoQQQgiRp0mwkwepVKpUv6ZMmZJlbWnSpImxXq1WS+HChWnfvj1r165Nd1lTpkyhevXq5m+kEEKIPE2CnTzo/v37xq85c+bg7OxskjZu3DhjXkVRiI2NtWh7hgwZwv3797l+/Tp//fUXFStWpGfPngwdOtSi9QohhLCs5zF6FEXJ7ma8lAQ7eZCnp6fxy8XFBZVKZTy+fPkyTk5ObNu2jVq1aqHVajl06BADBgygU6dOJuWMHj2aJk2aGI8NBgPTpk2jRIkS2NnZUa1aNf7888+Xtsfe3h5PT0+KFClCvXr1+Pbbb/nxxx/5+eef2b17tzHfRx99RNmyZbG3t6dkyZJMmjTJOBtq8eLFTJ06lXPnzhl7ihYvXgzArFmzqFKlCg4ODnh7e/Puu+8SERGR6ddRCCFEym4+fkaFydsZtfJsdjflpWSdnXRSFIXnOn221G1nrTHbLKEJEyYwc+ZMSpYsSb58+dJ0zbRp0/j9999ZuHAhZcqUwc/Pj7feeouCBQvSuHHjdNXfv39/PvjgA9auXYuvry8ATk5OLF68GC8vL/7991+GDBmCk5MT48ePp0ePHpw/f57t27cbAyQXFxcA1Go133//PSVKlODGjRu8++67jB8/nvnz56erTUIIIdJu8ZFAADadu8e8XjWytzEvIcFOOj3X6ak4eUe21H3x85bY25jnLfv8889p3rx5mvNHR0fz9ddfs3v3bnx8fAAoWbIkhw4d4scff0x3sKNWqylbtiyBgYHGtE8//dT4ffHixRk3bhwrV65k/Pjx2NnZ4ejoiJWVFZ6eniZljR492uS6L7/8knfeeUeCHSGEsCBNLlqiQ4KdV1Tt2rXTlf/atWtERkYmCZBiYmKoUSNjEb2iKCY9VatWreL777/n+vXrREREEBsbi7Oz80vL2b17N9OmTePy5cuEh4cTGxtLVFQUkZGRshikEEJYiEYtwU6eZWet4eLnLbOtbnNxcHAwOVar1UkGmSVePTh+DMyWLVsoXLiwST6tVpvu+vV6PVevXqVOnToAHD16lD59+jB16lRatmyJi4sLK1eu5Lvvvku1nMDAQNq1a8fw4cP56quvcHNz49ChQwwePJiYmBgJdoQQwkJy0+KrEuykk0qlMtujpJykYMGCnD9/3iTt7NmzWFtbA1CxYkW0Wi23bt1K9yOr5CxZsoSQkBC6du0KwJEjRyhWrBiffPKJMc/NmzdNrrGxsUGvNx0vderUKQwGA9999x1qddx4+9WrV2e6fUIIIVKnyUVTnPLep7bIkDfeeIMZM2awdOlSfHx8+P333zl//rzxEZWTkxPjxo1jzJgxGAwGGjRoQFhYGIcPH8bZ2Zn+/funWHZkZCRBQUHExsZy584d1q1bx+zZsxk+fDhNmzYFoEyZMty6dYuVK1dSp04dtmzZwrp160zKKV68OAEBAZw9e5YiRYrg5ORE6dKl0el0zJs3j/bt23P48GEWLlxouRdKCCFeQVE6PXsvP+D10gVwsYv7I/hlY3b0BoUDVx5Q3tMZL1e7rGhminJRXCYsqWXLlkyaNInx48dTp04dnj59Sr9+/UzyfPHFF0yaNIlp06ZRoUIFWrVqxZYtWyhRokSqZf/8888UKlSIUqVK0aVLFy5evMiqVatMBhB36NCBMWPGMHLkSKpXr86RI0eYNGmSSTldu3alVatWNG3alIIFC/LHH39QrVo1Zs2axbfffkvlypVZvnw506ZNM98LI4QQgq+3XuLd5acZvPiEMe1lj7GWH7/JoMUnqf/NXs7cCrF0E1OlUnLDakAWFh4ejouLC2FhYUkGxEZFRREQEECJEiWwtbXNphaKrCbvuxBCJKg4eTuRMXHDCAK/aQvA93uuMmvXFZO0xDrPP8yZW6EA1C+VnxVD6pm9Xal9ficmj7GEEEIIkarkukWSm4117MZjonR6LtwLNwY6KeXNStn6GGvatGnUqVMHJycn3N3d6dSpE/7+/iZ5oqKiGDFiBPnz58fR0ZGuXbsSHBxskufWrVu0bdsWe3t73N3d+fDDDy2+BYIQQgjxqlBIGu2oEz3GCnuuY92ZO/T86RgDFp1gxg7Tz/LsnrmVrcHOgQMHGDFiBMeOHWPXrl3odDpatGjBs2fPjHnGjBnDpk2bWLNmDQcOHODevXt06dLFeF6v19O2bVtiYmI4cuQIS5YsYfHixUyePDk7bkkIIYTIM6J0es7cCiFKZ0hyzu/KQ+P3o1eeYcyqc6mWk52y9THW9u3bTY4XL16Mu7s7p06dolGjRoSFhfHrr7+yYsUK3njjDQAWLVpEhQoVOHbsGPXq1WPnzp1cvHiR3bt34+HhQfXq1fniiy/46KOPmDJlCjY2Ntlxa0IIIUSupDco3AmJpFh+B3r8dIxzt0OT5Al5FsPRG4+Nx/v8HybJk5jWKnvnQ+Wo2VhhYWEAuLm5AXFrqOh0OuPeSQDly5enaNGiHD16FIhbjK5KlSp4eHgY87Rs2ZLw8HAuXLiQbD3R0dGEh4ebfAkhhBACxq4+S+MZ+1l7+k6ygQ5A14VH0lVm8fwOL89kQTkm2DEYDIwePZrXX3+dypUrAxAUFISNjQ2urq4meT08PAgKCjLmSRzoxJ+PP5ecadOm4eLiYvzy9vY2890IIYQQudOGs/cAmL//erLnrwY/5cbDZ8meS8myYzdfnsmCckywM2LECM6fP8/KlSstXtfEiRMJCwszft2+fdvidQohhBC5SUoTqP6371qGynvwNCoTrcmcHDH1fOTIkWzevBk/Pz+KFCliTPf09CQmJobQ0FCT3p3g4GDjzteenp78/fffJuXFz9Z6cXfseFqtNkP7OQkhhBCvCnUKM6jie37S63lM9g1SztaeHUVRGDlyJOvWrWPv3r1JVuKtVasW1tbW7Nmzx5jm7+/PrVu38PHxAcDHx4d///2XBw8eGPPs2rULZ2dnKlasmDU3IoQQQuQx5p4uHvZc9/JMFpKtwc6IESP4/fffWbFiBU5OTgQFBREUFMTz588BcHFxYfDgwYwdO5Z9+/Zx6tQpBg4ciI+PD/Xqxa3E2KJFCypWrEjfvn05d+4cO3bs4NNPP2XEiBHSe5NFBgwYQKdOnYzHTZo0YfTo0Zkq0xxlCCGESBtFUYiJNZ1ebu51AMOfZ9/6d9ka7CxYsICwsDCaNGlCoUKFjF+rVq0y5pk9ezbt2rWja9euNGrUCE9PT9auXWs8r9Fo2Lx5MxqNBh8fH9566y369evH559/nh23lKMMGDAAlUqFSqXCxsaG0qVL8/nnn1t8wcW1a9fyxRdfpCnv/v37UalUhIaGZrgMIYQQmfPxuvNUnbqD+2HPjWkpPcbKKGe77Bs5k61jdtKyLZetrS0//PADP/zwQ4p5ihUrxtatW83ZtDyjVatWLFq0iOjoaLZu3cqIESOwtrZm4sSJJvliYmLMtiZR/NIB2V2GEEKItPnj71sAfLPtsjHtxZ6ejJjVvRprT9+lZSUPqhZxzXR5GZVjZmMJy9BqtXh6elKsWDGGDx+Or68vGzduND56+uqrr/Dy8qJcuXIA3L59m+7du+Pq6oqbmxsdO3YkMDDQWJ5er2fs2LG4urqSP39+xo8fnyRoffERVHR0NB999BHe3t5otVpKly7Nr7/+SmBgIE2bNgUgX758qFQqBgwYkGwZISEh9OvXj3z58mFvb0/r1q25evWq8fzixYtxdXVlx44dVKhQAUdHR1q1asX9+/eNefbv389rr72Gg4MDrq6uvP7669y8mb3TIYUQIjs8jojmk3X/cv5umEl64sHH/sFP01xezzpJl3CZ1qUKXWoW4fe369LXp3iG22oOEuykl6JAzLPs+TLDBvV2dnbExMQAsGfPHvz9/dm1axebN29Gp9PRsmVLnJycOHjwIIcPHzYGDfHXfPfddyxevJjffvuNQ4cO8eTJE9atW5dqnf369eOPP/7g+++/59KlS/z44484Ojri7e3NX3/9BcQNPL9//z5z585NtowBAwZw8uRJNm7cyNGjR1EUhTZt2qDTJQx4i4yMZObMmSxbtgw/Pz9u3brFuHHjAIiNjaVTp040btyYf/75h6NHjzJ06NBs369FCCGyw4S1/7L8+C3azTtklvJaVymUJM3eRmOWss0hR0w9z1V0kfC1V/bU/fE9sMnYKpSKorBnzx527NjBe++9x8OHD3FwcOCXX34xPr76/fffMRgM/PLLL8YgYNGiRbi6urJ//35atGjBnDlzmDhxonF/soULF7Jjx44U671y5QqrV69m165dxpWwS5YsaTwf/7jK3d09yeKR8a5evcrGjRs5fPgw9evXB2D58uV4e3uzfv163nzzTQB0Oh0LFy6kVKlSQNySBvFjt8LDwwkLC6Ndu3bG8xUqVEj/CymEELncg6dR7LoY/PKM6aBJ5g9Hc4/5yQzp2cnjNm/ejKOjI7a2trRu3ZoePXowZcoUAKpUqWIyTufcuXNcu3YNJycnHB0dcXR0xM3NjaioKK5fv05YWBj379+nbt26xmusrKyoXbt2ivWfPXsWjUZD48aNM3wPly5dwsrKyqTe/PnzU65cOS5dumRMs7e3NwYyAIUKFTIuSeDm5saAAQNo2bIl7du3Z+7cuSaPuIQQ4lXRZMZ+s5eZ3Myt7FxX50XSs5Ne1vZxPSzZVXc6NW3alAULFmBjY4OXlxdWVglvuYODaS9RREQEtWrVYvny5UnKKViwYPrbS9xjs6xibW1tcqxSqUzGEy1atIhRo0axfft2Vq1axaeffsquXbuMyxgIIURe8jxGT8cfDuFTMj9TO1ZGp48bcByZRUFIKffs3Q8rMQl20kulyvCjpOzg4OBA6dKl05S3Zs2arFq1Cnd3d5ydnZPNU6hQIY4fP06jRo2AuLEwp06dombNmsnmr1KlCgaDgQMHDphs6BovvmdJr0/5P1+FChWIjY3l+PHjxsdYjx8/xt/fP90LR9aoUYMaNWowceJEfHx8WLFihQQ7Qog8afM/97gSHMGV4AiaV/TkrV+PJ5tvdzofaU3tUInPNia/0TbA6mE+PHwaTa1iOWdWrTzGEkZ9+vShQIECdOzYkYMHDxIQEMD+/fsZNWoUd+7cAeD999/nm2++Yf369Vy+fJl33303yRo5iRUvXpz+/fszaNAg1q9fbyxz9erVQNyyASqVis2bN/Pw4UMiIiKSlFGmTBk6duzIkCFDOHToEOfOneOtt96icOHCdOzYMU33FhAQwMSJEzl69Cg3b95k586dXL16VcbtCCHyrFhDQs92SoEOwNtLT6ar3H4+xVI9X9HLmbZVkw5Yzk4S7Agje3t7/Pz8KFq0KF26dKFChQoMHjyYqKgoY0/PBx98QN++fenfvz8+Pj44OTnRuXPnVMtdsGAB3bp1491336V8+fIMGTKEZ8/idswtXLgwU6dOZcKECXh4eDBy5Mhky1i0aBG1atWiXbt2+Pj4oCgKW7duTfLoKrV7u3z5Ml27dqVs2bIMHTqUESNGMGzYsHS8QkIIkXuYYQJvsl42izW5wcoYMr9mT2aolLSs7JfHhYeH4+LiQlhYWJLHN1FRUQQEBFCiRAlsbW2zqYUiq8n7LoTIze6ERNLg230WKTvwm7YUn7DFJG3F23Xp/Utc75H/l63QWv037XzHJ3D0f+BRGYYfNntbUvv8TkzG7AghhBB5zKydV7KtbrU+Gq7tg5W9ExKDz8O9M+BVI3valC21CiGEEMJsdl0MpsmMfZy7HQqAIRse2tgTxYdWK7GeVsg00AHovQYKVc/yNsWTnh0hhBAil9jv/4Dlx2/xVefK/HjgBk+exTCrezWG/DfIePCSk5z8NOnMV0sqr7pFndXDuWgblvRkuzlQe2CWtic5EuwIIYQQucSARScAsNGo2fJv3MKowxonrEr/KCKaI9ceZWgrnG+7VuGjv/5NU96lrz9i87F/+dBqNQVVYRDzQobSvvDmEtA6prsdliDBThrJOO5Xi7zfQoic7HZIpPH7Z9Gm65T1/uU4nWsUTld5bzcoQY86RVMNdha+VYuyBW1hdX8aXVxPoxcmw/obivCRbijrvx4VtyZdDiLBzkvET22OjIzM0tWARfaKjIz7RZLWqe1CCGEuYc91ONtapdo7ExNrSPb7jPq03csWaFVoZXseFnRNeqpcG05W+oRuK27GHeewQAck2HkpjUaDq6urcY8le3t72Sk7D1MUhcjISB48eICrqysaTc7ZtVcIkfcdu/GYnj8d481aRZjxZrUU88Vv/QAQo08a7Gz91zx7/1kRy3tW63jfah38nuhE8YbQYHTcv1Za1LdCgJtmqdMSJNhJA09PTwBjwCPyPldXV+P7LoQQWeX7PVcBWHPqjkmws/LvWxQvkLBV0fWHz4zfJ7fhZnQ6entm90gaVJVU3WOe9TwqqZMJYDr8D2r2NUmq4e3Km7WKUCx/+vdwzAoS7KSBSqWiUKFCuLu7o9Ppsrs5wsKsra2lR0cIkS0SPzj4bqc/H7Qox4nAJ0xYm/JYmjuJxu9kROcaRYzf17S+xVtspovmkEmeawYvSneaCFXeBOukQzpUKlWqPVHZTYKddNBoNPIhKIQQwmJUJEQ78/Ze44MW5bjxMOmegYn5Bz3NfMWx0XD4e9ZqvjRJDlLy0Tp6GiE4E1izbebrySYS7AghhBA5wIdrznHo2qMk6TH61GeHrjl1J8N1vlbCDfZ/C/u/Nj3hMxJqD+KnI9GEHA7IcPk5hQQ7QgghRDYLePQsxaAlNpkByJmlwsA863m0u38cXhzLPHS/cVuH1lWe8NvhADydc/cegRLsCCGEENnAYFBQq+MeWx3wT34CzMGrD5m66aJZ6/2uTSEa7+lIAVW46Ym31kLpZiZJdYq7sXNMI7xcc/fSK7LrOWnfNVUIIYTIjCidnpuPIwmNjGHwkpNMbleR7nW8k+wibgkVVYF8Zr2UuurLpif6roNSb1i8fkuQXc+FEEKIHKbfr3/zd+AT4/H4v/6hex1vC9ao8K5mAx9YrUGjMu3bCC3UENdBa5KdXZXXSLAjhBBCZJHEgU68sOcpL2lio1Enu2hgWtRS+fOXdmqSdH259mgajsa1SO0MlZsbSbAjhBBCWIDeoHA/7DlF8qW+0F61qTtTPGdrnf5gp7P6ILNtFpikhdkW5sunbbnk0Z7NvRqlq7y8QIIdIYQQwgJGrzrLpnP3+KF3TdpWLZShMsKjYtOct7bqMn9qP0964o1JODf8gCEPIihVMGfsQp7VJNgRQgghzCQyJpZfDwbQsrInm87dA2DBgWsZDnZexpZoxlj9yTCrpAOcTxjKUuezI6CxRgWU9XCySBtyAwl2hBBCCDP5bucVfj0UwHe7rhjTNGo1ADsvBJm1rhqqq6yxmYqVKuljro7Rn3NOKU2gxtqsdeZWEuwIIYQQZnLqZkiSNKv/1tIZuuyUGWpQmGD1B+9YbU56qkQj6L2aceuvcO7UHTyctWaoL2+QYEcIIYR4iTshkZy+FUrbKoXQqFUp5ktu6brkAqD0siWa0VZ/JRvkTNQN5v33J+Dp7g7AZ+0rUt7TidZVLPPoLDeSYEcIIYR4iQbf7gPgeUwsPeoUTTGfIYVlelvN8ctw3T7qC/xh81WS9BsGT9rGfM1zbBln72JMd7K15u2GJTNcX16kzu4GCCGEENnt2oMIWs89yLZ/X9woytTR649Nju+GPifw0TNjj44+hWjncjp3JtcSwxSrxQTa9k4S6HyqG0jxqBW8ETOL58TtWWVtJR/nqZFXRwghxCtv7OqzXLofzvDlp1PNp1YlPMIKeRbD69/spcnM/czedYVTN0NSDHbSTmGm9UL8bQcwwMp0/Z0PdUPZ39Of3/XNk1xlo5GP89TIYywhhBCvvPBUVjFOTJUo2Ln2MML4/fd7r/H93muZakMxVRAHtGNN0qIVK/7UN+bL2D48x5Z2ao3xXMMyBTh49REA1hLspEpeHSGEEK+8xEFMYrsvBhP46JnxOJWxyRlmSzS1VP5JAp2JusGUi17KJ7GDjY+r1Cr4tmsVGpYpwOwe1dFaqfF0tk110LSQnh0hhBCC5EKFw9ce8fbSkyZpapWKy0Hh/OR3g9LumV+NOLmtHe4q+dlTdxF/+EUkya9WqehRp6hxkPS5z1qYPFoTyZNgRwghhEjGycCkU8ZXnbzNqpO3M122j/oC31j9TDH1A5P07tGT+FupwNHXX6NMuUjsbTQEh0cZ1+gpks90h3Jbaw3i5STYEUIIIRLRGxQ0ahX6ZNbMyTyFX61n0kxzxiR1dMy7rDe8Tnwfk7VGjU+p/Mbza9+tz5OIGIrld7BAm/I+CXaEEEKIRKpN3cn7zcpgyPTMKlM9NPv41vpnk7Rx6g/5M7JGkrwvPpqqWTSfWdvyqpEBykIIIUSi2CIiOpavtl4yW8+OlhjGWP1pEuj8YyhB1aif6NX/XZO89Uvl5/XS+clnL3tamZP07AghhBDJyGzPjpYYttpMpJQ6YaHCh4oLXWOmcEvxAKC0u+lO5MvfrgukPDtMZIz07AghhHjlnAh8Qr2v97D9fFwgklxocfF+eIbLz0c4/rYDTAKdnWU+Y0D+5ZSrUNWYZq0xrVmlUkmgYwHSsyOEEOKVM+C3v3kWo+ed30/zRnl3rj98liRP/IJ96TXeaiXvWm00Hm/W12OSbgBn+vSiBTBsWcJ09sRjc5qWK5ih+sTLSc+OEEKIV06kTm/8fu/lB6nkTJ8vrX41CXS+1fVkpG4UITgb0+qWiJtlZaNRmwQ77zUrY7Z2CFPSsyOEEOKVY+5Z5Q48Z7nNV1RX3zCmRQw5yoJ5AUny9vUphrOdNfVKusnKx1lEgh0hhBAiE97VbGC89SqTtJpRCznlVQFIGuxYa9R0q1UEwLhburAseYwlhBBCZFAH9eEkgU6D6DlYORVM00BjGYycNaRnRwghhEgnB56zUzuewqrHxrTxuiGs1jcF4P3Xiqa7TCt5pGUxEuwIIYQQ6ZCPcM7YvmM8vm4oRIeYL3lGwr5VDcoUSHN5Pet4cy8sispeLmZtp0ggwY4QQog873FENJ+uP0+FQs7ULpaxrRd61Pbm+elVfG/zP2NaiOLI1Y4bmGblxMnAJ7zbpDR3QiKpXdwtzeV+07XqyzOJTMnWMTt+fn60b98eLy8vVCoV69evNzkfERHByJEjKVKkCHZ2dlSsWJGFCxea5ImKimLEiBHkz58fR0dHunbtSnBwcBbehRBCiJzm9K0QQp7FAHGDgGt9uZtt54OYtesKUzddTHd5VsQy4NmvJoHOD7EdePzuJVrVKkeHal583rEyni62JoFONW9XAOoUl72tslO2BjvPnj2jWrVq/PDDD8meHzt2LNu3b+f333/n0qVLjB49mpEjR7JxY8IaBmPGjGHTpk2sWbOGAwcOcO/ePbp06ZJVtyCEECIHOHUzhCvBTwHwu/KQLvOP0GTmfgBe3PXB/798aeXJY45rR1AhYLExrXfMx+wrPJzSHs4pXwj83K8WH7Uqz4K3aqWrTmFe2foYq3Xr1rRu3TrF80eOHKF///40adIEgKFDh/Ljjz/y999/06FDB8LCwvj1119ZsWIFb7zxBgCLFi2iQoUKHDt2jHr16mXFbQghhMhGYZE6ui44AsD5qS3Zcymudz/suQ6AWIMhw2W3UJ/gJ5vZxuNo+0JUfvItOqx4r1T+l17v7mTL8CalMly/MI8cPfW8fv36bNy4kbt376IoCvv27ePKlSu0aNECgFOnTqHT6fD19TVeU758eYoWLcrRo0ezq9lCCCEs7NqDp7y95AT/3Akl9HmMMX3PpWBi9AnBzZZ/7vPmwox9HlRSBZoEOrc8m6MdfxmdDHfNdXL0OzZv3jyGDh1KkSJFsLKyQq1W8/PPP9OoUSMAgoKCsLGxwdXV1eQ6Dw8PgoKCUiw3Ojqa6Oho43F4eMY3exNCCGF+UTo9q0/epmk5d7zd7E3O7b0czKDFcftL7b70gL0fNDaee3/lWZO8I1aczlD9o63+ZLTVWuPxl7o+9HtzZobKEtkvxwc7x44dY+PGjRQrVgw/Pz9GjBiBl5eXSW9Oek2bNo2pU6easaVCCCHMafbuK/x44AZ21pe59EUrY/rjiGhjoBNP/+KgnExRWGL9LY01/yS0RdeVvmNnUDS/fSrXiZwsxwY7z58/5+OPP2bdunW0bdsWgKpVq3L27FlmzpyJr68vnp6exMTEEBoaatK7ExwcjKenZ4plT5w4kbFjxxqPw8PD8fb2tti9CCGESJ/D1+J2HH+u0xOrN2CliRt18SxanyRvrJmCnVGatYy1/tMkzdBvM6OKN5A9rHK5HDtmR6fTodPpUKtNm6jRaDD8N9isVq1aWFtbs2fPHuN5f39/bt26hY+PT4pla7VanJ2dTb6EEELkTGNXnzN+/9fpO0nOZ7ZnR4OeKVaLkwQ6jDyFumRDCXTygGzt2YmIiODatWvG44CAAM6ePYubmxtFixalcePGfPjhh9jZ2VGsWDEOHDjA0qVLmTVrFgAuLi4MHjyYsWPH4ubmhrOzM++99x4+Pj4yE0sIIfKIjefuMePNqvx2KJC5e64mOZ+Znp2ChLBNO5ECKtOxm9EjzqAtUDLZa3q9VpTN5+7Rt16xDNcrsla2BjsnT56kadOmxuP4R0v9+/dn8eLFrFy5kokTJ9KnTx+ePHlCsWLF+Oqrr3jnnYRlumfPno1araZr165ER0fTsmVL5s+fn+X3IoQQwnJ+ORjAjB3+yZ7TZ2BquTMRVFEHMMd6vkmg4xs9nUDFk0tuxVO8dlqXKnzRsZLx0ZrI+VSK7C9PeHg4Li4uhIWFySMtIYTIAjN2XOZeaBSzuldLdufvdvMOcv5uoiCkgge7LyW/On5hVzvuhj5PU70FCeGE7Ygk6ev19flANxw9GgACprWRHclzgbR+fufYAcpCCCHyrh/2XQdgcIMSVC6csAHmtQdPGfXHWS7eN32sZEjl7/K0BDqOROKjvsiX1r8lOfdRsZWs8o/rHTo3uQVqNRLo5DES7AghhMg20bGms6vGrj6XJNAB2Hv5QabqOW/7dpK0s4aSFO05i5IPi4L/ZQBc7K0zVY/ImSTYEUIIkaUMiQYUK0rcRp2KAmq1ivD/tngwBwee00uzl64aP5P01bGNGR87FFBxutjrDCxrhVqlolHZgmarW+QsEuwIIYTIUvpEj6QUoOuCI+gVWDe8vlnrGWq1hfcTrYIMMLfyWmafjDIeW2tU2FipGdIo+ZlXIm+QYEcIIUSWSrwuTsizGE7fCgXg8bOYFK5IOwee00R9jt6aPbyuuWBMv2QoSpuYr7nauSmzT24zplvLjKpXggQ7QgghstTV4Ajj94kDn9Unb2eqXGee8Y/tEJO0aMWK7jGTOaeUAlRJFgi0kWDnlSDvshBCCIsJj9IRER1rkjZm9Vnj97suJkwnn7HDnycZ7N2pp76YJNBZGtucqtG/cE4pDcQFOS/OslLL6sivBOnZEUIIYRHRsXqqTtkJwPWv2xATa8DORsOjiGhjnrVn7ppcEx5lGhi9TEFC2Kf9AEdVwjicyy4N+CqqGwej3DPRepGXSM+OEEIIs/p66yXGrTnHw6cJQc2vh25QYfJ2Np27R2ikOWZcKcywWsgJ2xEmgc4UXT+KjtjAfa3pgOMVb9fl2MRmZqhX5EbSsyOEEMJsFEXhJ78bAHSqXtiY/vXWuHVs3vvjjFnq+cBqDW9amU4pH2A7i7nj+2FvY4Um0eOqIxPewMvVziz1itxJenaEEEKYjU6fMOA4NgN7Vr2MDTpmWi/kPav1xrR1+tcpHrWC29aljIsCJh6ak1Kg836zMmZvn8iZpGdHCCGE2SQOcL5PZofyjFNYaD2HVpoTJqnlohYTjc1/dScEWi/OukqO1lr+3n9VyDsthBAiw87fDWPWris8j4nb9kEXmxBwxK+fk1mFeEygbR+TQGdJbHPKRC01BjoAsfr0BTuyDfarQ3p2hBBCpNvY1Wd5+DSag1cfARCrNzCscSlG/nHarPU0U5/iV5vvTNJ8o6czoW8navjd4O/AJ8b0xGv2qFPZyLNiIWcu3g+nTZVCZm2ryLkk2BFCCJFua0+bThm/cC+c2buuGIMfc9ASYxLobNfXYYRuFHo0+Fb0MA6Ejpf4EVq1Ii6cvR2abLkbRr5O+HMd+R21ZmuryNkk2BFCCJEuIcks/KcA90Kfm6V8DXp81af4znphXIJKAx8F8s6Ugyb5OlT3MunZSTxm58NW5XGytU6298Zao5ZA5xUjwY4QQoh06fnTsSRpflcemqXsfIRzxvYd08RW34CtMwWdtCZr9/R+rSglCjjQ55fjAOgTjdlx1FoxrmU5s7RJ5H4S7AghhEiTKJ2eXReD8Q9+avayrYjlU6vfGWC10yQ9uvk3aOsOBTBZOwfitnp4vXQB47HOAlPdRd4gwY4QQog0mbb1EkuO3jR7uVbEcs22X5L0MTHDmVYnYb+rom72BIVHJckXL/EAZSESk6nnQggh0uTFQcnmYEdUkkBnerlVFI9awTpDQzSJdiX/rns13ijvzoohdZMtK/GChkIkJsGOEEKINDF3KFFOdYtLtoNMEz99QJhtwjYTiR9debvZ89uAOtQvVQAh0kOCHSGEEC+l0xuIiTXfmJiChLJDO8EkrbvHFrDSYki02p86DYsDLuhTExc7a5YOes1s7RN5i4zZEUIIkSq9QaHR9H3E6M0T7NgSzQnbd43Hn+v6ovJ5l3mN4nYqf6teMf74+za+FdzTVF7rKoVoVdkTVSoLCYpXmwQ7QgghUhUSGcP9sJQHBqeHHVEmj66WxDZH4zOcT9pVNKZV8nLh6MQ3KJCOtXAk0BGpkWBHCCEEELflA4CVxnSEQ2pbL6RVdW9XPnLcgk/AD8Y0f0MRPosdQGC7SknyF3JJfqdyITJCxuwIIUQedzX4KYMWn+CfO6Ep5ll35g6lP9lGhcnb2XD2LsOWnSQiOhYwz5TuwfYHTQIdgJYx3wLSIyMsT3p2hBAij+v329/cD4viwJWHXP+6TbJ5xqw6B8RN335/5VkAdny2g34+xXDQZvyjwp4oLtoOgheW56kb9T8k0BFZRXp2hBAij4sfb5ORHpqlR2+yYP/1dF/3TuNSVPaw5Yx2mEl6eOflxHwaQv9WPgC826RUussWIr2kZ0cIIfKge6HPefA0murersme1xsUQiNjLLIhZsmCDkyoqSf0xGC0Kl3CicG7cPaOmx4+vHEp2lf1okg+GZsjLE96doQQIg+q/81eOv1wmKsp7GM1dOlJan25m3/vhJm97lLRl2FBfVwNIQCcNJSFKWHgnbAOjkqlwtvNXmZRiSwhwY4QQuRhZ2+HJpu+5/IDAJYdCzRjbQqt1cf5OeYjY8rHusF0i5lixjqESD95jCWEEHlYcqN0zt9N6M0xx7Ty+JpmW8+ns+awMcXPrSsr7jUzU/lCZJwEO0IIkZclE+20m3co4bQCfwc8yVDRm0Y2wF6r4X+zv+Rz68U4qZ4nnOy5gm0Xi8K9WxkqWwhzkmBHCCFyEb1B4cbDCEq7O6ZpvIvyQrTjO+uAyfGqk7dZdfJ2utvxWfuKVHHTww+1mW3zwJh+2qEhzm8tpXQhN3o7hvHH37d4rbhbussXwpwk2BFCiFzk0/Xn+ePvW4xvVY53m5R+aX7lhZ6daw8izNKO5hXcYXYZ0D0zpsXU/4Cavp+COm44aJUiLvz9cTPcHGzMUqcQGSUDlIUQIhf54++4x0Jzdl01SX8UEY3yYmRjMQqFfq2ZEOgUeQ0mP8GmxWRjoBPP3dk2yfYTQmQ1+QkUQohcIjbxruOJnmDtvhhM7S93M3HtvzyLjmXi2n+M5yas/desbWiuPkmgbR80z4ISEvtvArXGrPUIYU7yGEsIIXKJmTuvGL9PPFpn1q649JUnbuPpYssff6d/DM7L5CeMg44TsI99YV2e/pvB2tbs9QlhTtKzI4QQOVxYpI6/A56w8EDCtg3RsQaex+gBsNYkhD5Hrj02e/0DNNs5ZTvcJNCJrPs+THoMJRqavT4hzE16doQQIodrPdePe//tb5VYw+n7OPmpL+cSrYJcwClzg4F71y2KLtbAmlN3KMxDDtu+nyRPe+1vrGvRGWQsjsglJNgRQogcLrlAB+IGJb/ISWudqbq+6lSZ1Sduke/sAj62/sP0ZI/lxJRuzRqQQcciV5FgRwgh8hA7m8wNFFapVLxxbCA9rE+ZpB9tvh6fCk2RSeQiN5JgRwghcqj7Yc/RxaY+nXzZsZsmx4uPBGawNoV+mp0wtS8FFb0xtW/MBA4aqnKssk8GyxUi+0mwI4QQOZDBoOAzbe9L801afz6TNSk0U5/mV5vv4g8BiFBsaRA9l1CcALDSyO7kIveSYEcIIXKgWEPWLBA4z3oe7TXHTNJOvzaLLn4eJJ7gbqWWYEfkXjLCTAghstjy4zf5YvPFVFc8NlhgNeSZb1Yzfm+r0nFC+06SQIfxATwu3g7TlXxkQLLI3aRnRwghslCs3sAn6+IePTWv6EG9kvmT5Pn3Thj5Hc0/FNjLxZaAaW24cv4E5f5qbnLuE90gCtbtyWh7N6w1D5JcKz07IjeTYEcIIbLIs+hYqk7daTwOeRaTJM+JwCe8ufAoGjMEF7WL5ePkzRDjsU3sU1RbvqLcyd+MabHORanz4GNCcOY9W9e4fMn04pijPUJkF+mXFEKILNJ1wRH0icbixCTe6+o/ey7F9arozTBmx9U+oXeoiOoBtVdWh0SBDm2/w2rsv4TgDICDNu7vX2urhI+GEgUcqFLYRXp2RK6WqZ6dqKgobG1lTxQhhEiLy0FPTY5j9QrPY/R8u/0yLSt54lMq6SOtzHCxi1tg0J4oDmlHm570GQl13gZgXIuy7Lr0gLfqFQOgrIeTMdvusY1REbf+jhC5Vbp7dgwGA1988QWFCxfG0dGRGzduADBp0iR+/fVXszdQCCHyqhi9gV8P3WDxkUB6/Rw3UFjBfAOTbTQqJlot56LtINMTHwVCy6+MhyPfKMOGEa/j+F/PjoudNcc/bsbZyc3RqFWopVdH5HLpDna+/PJLFi9ezPTp07GxSegirVy5Mr/88otZGyeEEHmZTm/gbmjCVhDB4clvC5ExCiPvjGWY1RZjyuOKA2BKGNjle+nVHs62Jo/BhMjN0h3sLF26lJ9++ok+ffqg0SQsS16tWjUuX76crrL8/Pxo3749Xl5eqFQq1q9fnyTPpUuX6NChAy4uLjg4OFCnTh1u3bplPB8VFcWIESPInz8/jo6OdO3aleDg4PTelhBCWNT5u2FJ0nR6BUdtwu/Rzj8cZvWJ22apb6f7/ygccsJ4PE3Xi7v1p5qlbCFym3QHO3fv3qV06dJJ0g0GAzqdLl1lPXv2jGrVqvHDDz8ke/769es0aNCA8uXLs3//fv755x8mTZpkMk5ozJgxbNq0iTVr1nDgwAHu3btHly5d0ndTQgiRSd9uv8y4NeeSXTtn+/n7tJt3KEm6Tm9Aa5UQ7NwLiyIkMn2/RxOzJ4rvrecRaNubsuFHAbhs8KZi1G/8qG9vlkHPQuRG6R6gXLFiRQ4ePEixYsVM0v/8809q1KiRrrJat25N69atUzz/ySef0KZNG6ZPn25MK1WqlPH7sLAwfv31V1asWMEbb7wBwKJFi6hQoQLHjh2jXr166WqPEEJk1IL91wEY2qikyQBfgHd+P53sNaduhlDa3dEs9ddUXWGtdkqS9G11FhN5OK632xILFQqRG6Q72Jk8eTL9+/fn7t27GAwG1q5di7+/P0uXLmXz5s1ma5jBYGDLli2MHz+eli1bcubMGUqUKMHEiRPp1KkTAKdOnUKn0+Hr62u8rnz58hQtWpSjR4+mGOxER0cTHR1tPA4PDzdbu4UQr57EPSY6vQG9QWG//wOqe7tyO+R5itftuhiMdab3nFKS3fIB73owcBtj1GrmHo4bt+Nka53JuoTIndL9GKtjx45s2rSJ3bt34+DgwOTJk7l06RKbNm2iefPmLy8gjR48eEBERATffPMNrVq1YufOnXTu3JkuXbpw4MABAIKCgrCxscHV1dXkWg8PD4KCglIse9q0abi4uBi/vL29zdZuIcSrJ9aQsF7OnZDnLNh/jcFLTlLry910+uFwqtf+m8xYnrR4v1kZAH6xnpk00BlxAgbvAHXcr/hZ3asxvlW5JD1OQrwqMrTOTsOGDdm1a5e522LC8N8vj44dOzJmzBgAqlevzpEjR1i4cCGNGzfOcNkTJ05k7NixxuPw8HAJeIQQ6fb9nqsYFIVbTyKNacOWnUpXGQ+fRr88UzLett7GGNvJpomvDYU2M5Lk7VKzSIbqECKvSHewc+LECQwGA3Xr1jVJP378OBqNhtq1a5ulYQUKFMDKyoqKFSuapFeoUIFDh+IG+nl6ehITE0NoaKhJ705wcDCenp4plq3VatFqtWZppxDi1XT2diizdl3JdDlRuqSrKKdGSwzDNJtx2v+nSXqr6G/Y3mZ4ptsjRF6U7sdYI0aM4PbtpFMj7969y4gRI8zSKAAbGxvq1KmDv7+/SfqVK1eMg6Nr1aqFtbU1e/bsMZ739/fn1q1b+Pj4mK0tQgjxopDIpPtaWVoT9Vn8bQcw1to00Okd8zGXlaJZ3h4hcot09+xcvHiRmjVrJkmvUaMGFy9eTFdZERERXLt2zXgcEBDA2bNncXNzo2jRonz44Yf06NGDRo0a0bRpU7Zv386mTZvYv38/AC4uLgwePJixY8fi5uaGs7Mz7733Hj4+PjITSwhhVqGRMfzod4MuNQpTxsMJjYW3T6hX0o1jN54ACkM0W/BSPWag1Q7TTO8cYl2AFUc23LBoW4TI7dId7Gi1WoKDgylZsqRJ+v3797GySl9xJ0+epGnTpsbj+HE0/fv3Z/HixXTu3JmFCxcybdo0Ro0aRbly5fjrr79o0KCB8ZrZs2ejVqvp2rUr0dHRtGzZkvnz56f3toQQIlWfbbzAhrP3WLD/OoHftLX4LuCVvFw4duMJQzWb+dj6D9OTRepAvw1g40BHdwW1nTM1vF++KrIQryqVktwKWKno1asX9+/fZ8OGDbi4uAAQGhpKp06dcHd3Z/Xq1RZpqCWFh4fj4uJCWFgYzs7O2d0cIUQO1HjGPm4+jhuIHPhNW45cf0Tvn49brL6RTUtT5OB4elrtNz0x4gQULGuxeoXITdL6+Z3unp2ZM2fSqFEjihUrZlxE8OzZs3h4eLBs2bKMt1gIIXIw9QuPrV48NqeBmm2MO7rM9Dd01R5QZ4gEOkJkQLqDncKFC/PPP/+wfPlyzp07h52dHQMHDqRXr15YW8uCVUKIvEd5YXo5ZHzKeGrUGBio2c4k699NT7xzGDwrm70+IV4VGVpnx8HBgaFDh5q7LUIIkSPN3nUlyb5S7/1xxmzla4nhbc1WPrR+YRjAW39BqWZg4cHQQuR1aQp2Nm7cSOvWrbG2tmbjxo2p5u3QoYNZGiaEEDnF93uvmRyHPDPPtPN89tbUiTrCTzazTdKjFGts3z8BbiXMUo8Qr7o0DVBWq9UEBQXh7u6OWp3y0jwqlQq9Xm/WBmYFGaAshEhN8QlbzF6mBj2/287Eh3MAxCgaLjvVY3ZECxo268CghiVfUoIQwqwDlA2J9n1J/L0QQuRll+6H81xn/j/gSqvusFs73iRtkG48/VoP4NcKHqgtPK1diFdNulZQ1ul0NGvWjKtXr1qqPUIIYXEbzt7l10MBxuMj1x5x8V44h64+IvS/lZFXnbhF67kH6TL/iFnrtieKn62/Mx4fN5SnTNRSfJp3o3lFCXSEsIR0DVC2trbmn3/+sVRbhBAiS7y/8iwQt0qxk9aa3r+Yrpdjo1ETozd/L/YXVr/R12q38Xid9wTGXK1CaXcnRjQtbfb6hBBx0r031ltvvcWvv/5qibYIIYTFRMbEsuL4LYLDo4xp/94Jo9GMfUnyZjTQKVHAIWma6j7zrecQaNvbJND5UDeUVn3H823XqvwxRLa3EcKS0j31PDY2lt9++43du3dTq1YtHBxM/3PPmjXLbI0TQghz+XLLJVYcv0WR/XbGNHPsWh7vi46VWHwk0CStvfoI82z+lzSvrg/PK/XCzkZDjzqygacQlpbuYOf8+fPGjUCvXDH9RaGStSCEEDnUrovBANwJeW5MexoVa7byPV3sTFZV/qnQRlqErDTJ46evwlDdWKLQcq5TFbPVLYRIXbqDnX37knb5CiFETpfcKhsvLhSYGVZqlTHY+cjqD1qEbDKeC8pXmwb3RxGb6FeulUb+OBQiq6Qr2Fm1ahUbN24kJiaGZs2a8c4771iqXUIIkWkPn0ajUkEBR22ygU2sGZfScLS14v3SwbQJe9v0xKAdPFRXIPZ/h0ySLbm3lhDCVJqDnQULFjBixAjKlCmDnZ0da9eu5fr168yYMcOS7RNCiAyJ0ump81XcgOCrX7UmJFKXJE9GOnYGvV6C0MgY1p65a5LuffV36pyaZJp55CkoUBrV3bAk5UisI0TWSfNsrP/973989tln+Pv7c/bsWZYsWcL8+fMt2TYhhMiw0ETBzflkgo2MeqdJSey1GuOxG+H8Yj0Dz8OJAh2NFj59AAXippMXy2+fpJyXr10vhDCXNPfs3Lhxg/79+xuPe/fuzeDBg7l//z6FChWySOOEECKjEu9s09lMCwP+NqA27k62qFUqVBiYZ/0/2mmOmWbq8yeUaW6S5GRrzeEJb2CtUTFk6SlsrdTYWqd75Q8hRAalOdiJjo42mWauVquxsbHh+fPnqVwlhBBZKzQyhhErTlO/VAGzl21rHdejUzziLH9rJ1JQFZ5w0sYRBu0Az8rJXlvYNW7K+/p36wMye1WIrJSuAcqTJk3C3j6hOzYmJoavvvoKFxcXY5qssyOEyEoX7oXxs98NPmhRDm83e370u8Hha485fO2x2evSatQQfJFBV0dA4lhl7CVw9kpTGRLkCJH10hzsNGrUCH9/f5O0+vXrc+PGDeOx/CcWQmS1jv87TKxB4UpwBFvfb0iUBTbuBLAilvLb3oTgk8a03jEfc8RQmcA0BjpCiOyR5mBn//79FmyGEEJkTOx/U6r8g58C4GCT7uXDXkpLDP62AyA4IW1QzDiOGJJ/ZCWEyFlkhJwQIte4H/ac3ReDjQsExibawyp+HZ3EM6XMoYTqflygE8+tJHOrbmCvoaZZ6xFCWI75/wQSQggL8Zm2F4DpXatS0cuZ34/dNDkf9lzHfv+Hma6ncmFnrt59xHTrn+ioSZjJFVp1MK5dZmHndx24nOl6hBBZQ4IdIUSOdul+ODsuBDGsUSlj2vi//kk2b4Nv9vI0OnP7XRUklM2Pe4OtafqS2OZ0a/MtAP18ivP1Vgl2hMgtJNgRQuRoreceBCBK9/KtHTIb6DRQ/8vvNtNM0mKsnQkbdgZfKwccbK2BuCno9Uq6cezGk0zVJ4TIGukes6PTJV1yPd6jR48y1RghxKttw9m7tJztx42HEUnOXbhnvlWQk9NBfdgk0HmsODEoZhwHu5ykYIECxnVyhBC5T7qDnZ49eya7e3BwcDBNmjQxR5uEEK+o91eexT/4KRPW/gvAwauZH3+TFpOslvG9zQ/G4ynOU6kV/SN7DTUpXsAh2WtUyFIbQuQW6Q52bt26xdtvm+7qGxQURJMmTShfvrzZGiaEyJsMBoXvdvqz93Jwinmex8StlTN9u3+KeTLj5361UanAgycE2vZmsNU2AG4ZCtIoejanbWob85Yq6JhsGUXySU+PELlFuoOdrVu3cuTIEcaOHQvAvXv3aNy4MVWqVGH16tVmb6AQIm/Zdj6IeXuvMWjxyRTz/Hs3jJBnMdwPizKm3Xj4LNN1NyxTgHm9atC8jDOnC37BcduRxnPHnXzp5/Qz377dMU1lfdymAh2qefH74LqZbpcQwrLSPUC5YMGC7Ny5kwYNGgCwefNmatasyfLly1GrZdkeIUTqbodEpinf0GUneRQRbTy+G5q5ffjm9qxOx+qF4w4Ofke+8EvGc080Bag8bDH7HZ3SXF4+Bxu+71UjU20SQmSNDM3G8vb2ZteuXTRs2JDmzZuzbNky2SpCCJEm8Yv/QdzjKjub5BcBPBEYYrY6r33VGiuNGi5vBb8ZcO+08dyXuj58OmW+SX75bSZE3pKmYCdfvnzJBjORkZFs2rSJ/PnzG9OePJGpmEKIlMXqE4KdWl/u4uLnrQA4ddN8wc2LrDRqOLYAtk8wpukrd6dFQE8qFXGzWL1CiJwhTcHOnDlzLNwMIUReYzAoqNUJfySduvmEP0/d5XqiaeWRMXoWHrhOaKSOhQeuW6QdxZ1VsLofXNyQkNhtEZrKXditKNIrLcQrIE3BTv/+/S3dDiFEHrLs2E2mb7/M74PrUs3bFYCuC44mm/ebbRlfibhzjcKsO3M3xfOlVXfYHTMeLv6XoLGBcVfALh9AioFOiQIOnLtj2XV9hBBZJ0OzsXbs2JEkfefOnWzbts0sjRJC5G6T1p/naVQsY1efBeDMLcs8onq7YYlkUhU6qI/gr+3Pbu34hOTy7eDj+8ZAJzWT21fizVpFWPOOj/kaK4TINukOdiZMmIBer0+SbjAYmDBhQjJXCCFeVWqVirDnOjrPP/LyzBmgUauoUMgZgCqqG3xvPY9A2z58b/M/tKpEq72/uRh6LgdN2uZkuDnYMOPNatQpLuN5hMgL0h3sXL16lYoVKyZJL1++PNeuXTNLo4QQeYNKBdceJN36wWzlo+LDlmUppbrLJu2ndNCYPirbrK8L/TZCpc4Wa4MQIudL99RzFxcXbty4QfHixU3Sr127hoND8suqCyHyrvAoHU5aq2THv6hQ8TjRWjnmpn7+iPLHv2SP9k+T9CulB9Hq/BsYUNOuZGOL1S+EyB3S3bPTsWNHRo8ezfXrCTMnrl27xgcffECHDh3M2jghRM526X44VafsZOSKM8me9w9+yqoTty1StxoDhbcNxCsgIdCZpBtA8agVnK/4AYb0/3oTQuRR6f5tMH36dBwcHChfvjwlSpSgRIkSVKhQgfz58zNz5kxLtFEIkUP9cjAAgC3/3k8xz57LD8xapwoDfTS7uWH7FvYP4oKsVbFNKBe1mGX6FgB4utiatU4hRO6WocdYR44cYdeuXZw7dw47OzuqVq1Ko0aNLNE+IUQOptMbTI5/2HeNom72FquvICGcsB1hmth+Lo1K9yB62l5jkk/J/IxvVY5yHmnf/kEIkXdlaLsIlUpFixYtaNGihbnbI4TIRWJiE4KdE4FPmLHDMruUA7yj2cgE65UmaUqXn1FV7U6hF/KqVCrebVLaYm0RQuQuGXqofeDAAdq3b0/p0qUpXbo0HTp04ODBg+ZumxAih4tJ1LPz7vLTqeRMn5Of+hq/L6O6ww6b8UkCHYbsRVW1u/GwXdUXQx4hhIiT7mDn999/x9fXF3t7e0aNGsWoUaOws7OjWbNmrFixwhJtFELkUIl7dh4+Nd+sqwKOWtQYcCOcXdrxlFPfMZ4bGjOGqqyGwrVMrjEoyovFCCEEkIHHWF999RXTp09nzJgxxrRRo0Yxa9YsvvjiC3r37m3WBgohch6DQeHGowiTnp2M8nDWEhz+QqCki2K7zUeUVSdsBfGXvgGdP9tA+wsP+KxY0lWQ+9YrztZ/g2hUtmCm2ySEyFtUipK+P4e0Wi0XLlygdGnT5+HXrl2jcuXKREVFmbWBWSE8PBwXFxfCwsJwdnbO7uYIkS3uhT4n8NEz6pcu8NK807Zd4scDN8xS7/vNyjB3z1XjcRP1GRbbzDDJ87muL7/pWxP4TdtUy7of9pyCjtq4Xc6FEHleWj+/0/0bwdvbmz179iRJ3717N97e3uktTgiRzR6ERzHqjzPU/2YvvX85zrEbj1PNH6XTmy3QaV7Rg5FvJPzh1EF9xCTQ+UvfkJpRC/lN3zpN5RVysZNARwiRRLofY33wwQeMGjWKs2fPUr9+fQAOHz7M4sWLmTt3rtkbKISwrE/Wn2fXxWDj8d8BT6hXMn+K+b/dnvFdyl80rkU5rDVqDo5vypzvZzBd+eG/MyrovoR79yvyZNcVs9UnhHg1pTvYGT58OJ6ennz33XesXr0agAoVKrBq1So6duxo9gYKISzr1uPIdOX/69Sdl2dKgy2jGlDO0wkeX8f7F1++4wmoYEVsU3p/vhbUat6rCA8joll69KZZ6hRCvJoytM5O586d6dxZNtYTIi94cUurWbuu4OliS/fapo+lI2NieR6jR2/I/Kynn/vVppKXCzwNgnk1jen37MpRrvvPoE54FFWygOy5J4TInHQHOyVLluTEiRPkz2/azR0aGkrNmjW5ccM8z/KFEFlDncwGnuP//Mck2Pk74AndfzyaJF9GOdlagS4K5lZLSCzeEK9eK/HSOprk7VOvGIGPI2lU9uUDp4UQIjnpDnYCAwPR6/VJ0qOjo7l7924yVwghcrJkYh2j07dCWHIkkJOBIWat0/PBYVjaNyGhqA8M2JxsXmuNmikdKpm1fiHEqyXN0xY2btzIxo0bAdixY4fxeOPGjaxbt44vvviC4sWLp6tyPz8/2rdvj5eXFyqVivXr16eY95133kGlUjFnzhyT9CdPntCnTx+cnZ1xdXVl8ODBREREpKsdQrzKkuvZidfjx6NsOHuPu6HPzVZfKdVdim9PFOjUGgADt5mtfCGEeFGae3Y6deoExO05079/f5Nz1tbWFC9enO+++y5dlT979oxq1aoxaNAgunTpkmK+devWcezYMby8vJKc69OnD/fv32fXrl3odDoGDhzI0KFDZTVnIdJInUKsYzAo6PTmW5XYlmgWWc/AR3MxIbHbb1C5q9nqEEKI5KQ52DEY4lZKLVGiBCdOnKBAgcw/P2/dujWtW6e+fsbdu3d577332LFjB23bmi4odunSJbZv386JEyeoXbs2APPmzaNNmzbMnDkz2eBICAGKoqD6r0dHlULPzifr/81UHa+Xzs+iAa9R9tNtVFNdY4N2smmGniugfOqLBAohhDmke/WtgIAAswQ6aWEwGOjbty8ffvghlSolfWZ/9OhRXF1djYEOgK+vL2q1muPHj2dJG4XIbR5HRFP36z1M2XgBSLln54+/b2eqnuL5HbBBR13VJb6x/sWYrqCSQEcIkaXSHOwcPXqUzZtNBxAuXbqUEiVK4O7uztChQ4mONt9GgADffvstVlZWjBo1KtnzQUFBuLu7m6RZWVnh5uZGUFBQiuVGR0cTHh5u8iXEq2L58Vs8eBrN4iOBAJy9HWqReqwUHfxQl1XaL6igvhWX2HcdqimhEugIIbJUmoOdzz//nAsXLhiP//33XwYPHoyvry8TJkxg06ZNTJs2zWwNO3XqFHPnzmXx4sUpdrNn1LRp03BxcTF+yTYX4lXy4u7gZlg2B09nW5NjZ57x2YXWEBIAQKB9Fe50Xg+l3sh8ZUIIkU5pDnbOnj1Ls2bNjMcrV66kbt26/Pzzz4wdO5bvv//euKKyORw8eJAHDx5QtGhRrKyssLKy4ubNm3zwwQfGWV+enp48ePDA5LrY2FiePHmCp6dnimVPnDiRsLAw49ft25nrrhciN0k8+yqd+wAna3K7ikTGxBqPT7xTnHOOo1Dr/9sUuHw7io8/RJFqTTNdlxBCZESaByiHhITg4eFhPD5w4IDJ4OI6deqYNWjo27cvvr6+JmktW7akb9++DBw4EAAfHx9CQ0M5deoUtWrVAmDv3r0YDAbq1q2bYtlarRatVmu2tgqR0+j0BprO3E9MrIGDHzVFa6UxnjsekLDRZ3SsIdN1qVUJ5bRQn6Dg4t4JJ1tOg7rDMl2HEEJkRpqDHQ8PDwICAvD29iYmJobTp08zdepU4/mnT59ibW2drsojIiK4du2a8TggIICzZ8/i5uZG0aJFk6zSbG1tjaenJ+XKlQPi9uRq1aoVQ4YMYeHCheh0OkaOHEnPnj1lJpZ4pa05eYc7IXFr4yw6HMg7jUsBcPPxMw5fSxTs6DIf7KhUKnpXsuW1i1/RWnMi4UT3pVBR9ssTQmS/ND/GatOmDRMmTODgwYNMnDgRe3t7GjZsaDz/zz//UKpUqXRVfvLkSWrUqEGNGjUAGDt2LDVq1GDy5MkvuTLB8uXLKV++PM2aNaNNmzY0aNCAn376KV3tECKvefg0YbLAzcfPjN/HB0Dxxqw+m65yO1Tz4vzUllQs5GxMKxj2L5/5dzINdAbvkkBHCJFjpLln54svvqBLly40btwYR0dHlixZgo2NjfH8b7/9RosWLdJVeZMmTdI1ZiAwMDBJmpubmywgKPI8RVH4/fgtyro7Urdk/pfnJ+H/1R9/36ZxWXdaVfbEQWv6X37v5QcvXpoqg6LgqLVi6/sNKT5hC6VUd2lz/MOEDGVbge8UcK+QrnKFEMKS0hzsFChQAD8/P8LCwnB0dESj0ZicX7NmDY6OjilcLYTIjKPXHzNp/XkAAr9JmLYd/8fCizMWX/wb4p3fT1He04m3G5bMVDsSl9tfs4Op1ksSElp9A/WGZ6p8IYSwhHRvBOri4pJsupubW6YbI4RIXuDjyCRpiqLQ77e/CY+KZe3w+mj+Wx3wWXQs+688TJL/ctBTxq05l6l2qFSAXgcHvjUNdN49Du7lM1W2EEJYSrqDHSFE1ktuqalYg8LBq48AuPEwghi9gcv3n7Lm1G3OWWihwPIeDvC/2hASmJA4cJsEOkKIHE2CHSFygeS2dNAnWg0wIjqWzvOPWLQNpVV3GHFqFETGBVgUqgaDd4OVTeoXCiFENkv33lhCiKyXeEuH8Cgdnecf5me/G8a0r7deMltdC9+q9UKKwpua/ezWjkcV+Qg0Wmg9A4b5SaAjhMgVpGdHiBzucUS0yaacvx4M4MytUM7cCjWmnQgMMUtdwxqVpFXlhNXHy6lusUM7wTRTvw1QzMcs9QkhRFaQnh0hspmiKKw7c4fzd8OSPR8UHmVy/Cw6Ntl85jDyjdLG72uqrpgEOlFlO8LofyXQEULkOtKzI0Q2O3ztMWNWxc2SSjyt3GBQeHf5aWL0pqsc682wn1Vydo1phJNt3Cro72v+Yoz1Xwkn31qLbelmKVwphBA5mwQ7QmQz/+Cnxu9vP4nEy9UOjVrF6VshbL8QlCR/rN4ywU4ZD6e4b07+Zhro9PkLJNARQuRiEuwIkc0ST7RqOH0f7aoWom2VQugMyQc1On3m97NKVswzmFcLnt6PO/aqCYN2yCBkIUSuJ8GOENnsxWnlm/+5z+Z/7qeY/8XHWuZQ3sMRNoxMCHSK1Inb3yq5BX6EECKXkWBHiGyiKAp//H2bi/fD03WdLp2PseysNTzX6ZM9V8rZwPvVFNqfHwAXnsQlFigHb62VQEcIkWdIsCNEFlAUheXHb1GhkBO1isVtrbL9fBAfr/s33WXFxCYfuKRkTs/qDFt2Kkl6SdU99sSMg0SblVN/FLT4It1tEkKInEyCHSGywMGrj/j0hY08L9xLX49OvB0XgtOV38Yq6QoTndUHmW2zwDSx73oo2SRDbRJCiJxMgh0hssC1BxFJ0iw1hfxFNpqEYCe/gw39opfzvtW6hAzFGkCvFWCb/Ca/QgiR20mwI0QWSC6sWXH8VpbUrTGOgFbYWvIvPK4mBDqxnX/Fqlq3LGmHEEJkFwl2hMgCSjK9OGHPdVlStzo6nCGazXxivQKuJjox4TZWts5Z0gYhhMhOEuwIYWY6vYHBS05S3duVsc3LZmtbaqn8eW1Vb16zfuHEh9dBAh0hxCtCgh0hzGzPpQf4XXmI35WHhEXGcO5OGM0rehjPXw1+yn7/hxape0Lr8py7Hcq280F8arWMt622mWbovwlKNLJI3UIIkVNJsCOEmSVe9G/J0ZsAWCVaObD5bD+L1OuoteKdxqXg2m641tv0ZKUu0HkhWGktUrcQQuRksuu5EGamSWYxvpM3Q8xW/vvNyiRJa13Zky2jGsCOT+D3ribnHnT5C95cJIGOEOKVJcGOEGamsfD/qm61ipgcVyjkzII3y1LM/zc4+j9j+mPFiSbR3+FSsallGySEEDmcPMYSwszUFt5mQf3CZlrjKobDNNMAiDEXsbX1YJOioLXSWLQ9QgiR00nPjhD/0ekNGZ4OHh2rN04vt3Swk/gx2USr5TQ7nGh8TsVOMPIkuBTGQWuFk+2L07CEEOLVIz07Qvyn9dyDXHsQwd+fNMPdyTbN1wWHR1H/m734VnDH1lpjsfVzyns6Mb1bVdQqqK66xmfWS6mhvpaQoftSqNjRInULIURuJsGOEP+J39Jhv/9Dutf2TvN1q0/cRm9Q0r1nVXp927UqVQs5Eup/kPXayQknivpA/82gkf/OQgiRHPntKMQLklvtODU6Q9bscWUXHgC/NsE1UVrvmI9ZMeijLKlfCCFyKxmzI8QLEi2TQ1BYFBvO3kWXODGRKJ2e7/dcTfacORVRPaDY7qEmaV2ip/B6864pXCGEECKe9OwI8YLEu5G3mH2A8KhYHoRHM6RRySR55+01b6AT+E1bik/YYjy2JpZRVmt5z2o9/LdUT3SZtjT5txX3yc9PddL+uE0IIV5V0rMjxAsMiR5LhUfFAuB3NfntHc7eDrVYO4qqgrlq2y8u0Ik3YCsRHRdxn/wAWHbelxBC5A0S7AjxAoOiJBm3Y53MSoEGM4/VmdK+ovH7tzS78NOOMR7fVfJz582tUPx1k2uyZrSQEELkbvIYS4gXrDpxm6mbLpqk2SQKdhRFIUpnoNVcP24+jjRLneU9nRjwegkA1jV5QI1ji4znpuu6M1/fid0FqwHg5mBD3RJuAOR3sDFL/UIIkZdJsCMEpjOwLgc9TXLexkrNs+hYhi8/jd+Vh9jbaIiM0We4vmGNSlLEzZ5J688D8Cwm7nEZ+76mxrFvjfmiB+5h/oL4Ke1xbVSpVKwcWs/4vRBCiNRJsCNeWQGPnvE0SkfVIq4vHXtjrVHz+aaL+F2JG7uT0UBnQZ+alHJ3pKyHE4Ax2Al/HguXt8CBhECHjwJR27gA25KUI0GOEEKknQQ74pXVdOZ+AI5NbEbn+UdSzWutUbHyxO1M19m6SqEkaVbE8glLYOWOuATPKtB3PdjlQ5NoXJDscSWEEBkjwY545d14FPHSPOFROvLZWxMSmbatICoUcubS/fCX5ls0sA6xqwfTXO8Xl6B1hoHbQesIxG36OaF1eZ5G6fB2s09T3UIIIUxJsCNeedGxyS8YmNjWf4PSXN6cHtUpVdCR9v87lHrG2BiaXv4c4gMdgEE7jIFOvHcal0pz3UIIIZKSqefilReThmAnPdpWLYS11UvG1Oh1sHkMnFkWd1ygHEx6BB4VU79OCCFEuknPjnglJZ59Fas332o1C/rUxFqjxkqd9O+ISe3+C2TC7sLiNhASGHfc9BNo9CHIoGMhhLAI6dkRedKSI4HM3nUFgOhYPcuO3eTm42fG8/pEA39jDebr2YlffNAmmUUIm5UrCGsGwuyKCYFOx/nQeLwEOkIIYUHSsyPypM82XgCgeUUPlh4NZPXJO2jUKq5/3QYw3f/q/ZVnzVavtZX6v3+TBi8Fdr8H/msTEppMhBp9zFa3EEKI5EmwI/KcxNs43Hj0jNUn7wAJvTl/nbpDUHiUReq2VscFOYkfY5VW3WGi1R84+p9JyPjucXAvb5E2CCGEMCXBjshzYhMFO/dCn5ucUxSFD9acs1jdmv+CHeW/1Y5HW/3JaKtEvTkVOkDXX8BKa7E2CCGEMCVjdkSe890uf+P332y7bHIuLdPM06tiIWfj91aauGDHTf+E+dr/mQY6BctD54US6AghRBaTYEfkagZD0h3KfzxwI8X8zb47YPY2vNMkYR0cjVoNTwKwmlOBNqpEqzKP+BtGHAcbB7PXL4QQInUS7Ihc5cytEJrO3M+mc/fYdTGYRjP20f3Ho8aA59qDpJt4Jnb3hcda6ZHShClNohNWBh2s7muaodtvULBchusVQgiROTJmR+QaF+6FGfeweu+PhMG+d0KeExmjx0FrRe+fj1us/oBpbXnju/3cePjMJL1qERcABmu2UHlR74QTXX+Fip1AI//NhBAiO0nPjsg1Xhx/k9iUjRdQFIUHT6Mt24gX1h88OL4p7s5aBmu2MMl6ecKJWgOhSjcJdIQQIgeQYEfkGqmtdLzm1B22nU/7/lUZNatHdeP3b9YqgrebPdZbxpgGOr5ToP0ci7dFCCFE2sifnSLXeNlKx8uP3zRrfR+3Kc/XW+N6k0Y1KwNAdW9XbnzdhuhYA7ax4bBhBOozvxuviRzsh713NbO2QwghROZIsCNyjbshqQ8uPnztsVnrG9KwJPkdtDhoNbSqXCguUVFQH5mD3aXNcPekafsGnqGwd0mztkEIIUTmSbAjcryQZzE421lzL8wyqx6nRKVS0bVWkYQERYE/B8GFtaYZu/wCVbpRWPa3EkKIHClbx+z4+fnRvn17vLy8UKlUrF+/3nhOp9Px0UcfUaVKFRwcHPDy8qJfv37cu3fPpIwnT57Qp08fnJ2dcXV1ZfDgwURERGTxnQhLuXQ/nBpf7GLQ4hMWq6O0u2OStF6veZsmBJ2Hqa5JA503l0DVN2UjTyGEyMGyNdh59uwZ1apV44cffkhyLjIyktOnTzNp0iROnz7N2rVr8ff3p0OHDib5+vTpw4ULF9i1axebN2/Gz8+PoUOHZtUtCAsxGBSuPYhg2bG4cTgHrjy0WF3JhSnvNysb9030U/jFFxa+bpphwm2YEgaVOlmsXUIIIcxDpby4/Gw2UalUrFu3jk6dOqWY58SJE7z22mvcvHmTokWLcunSJSpWrMiJEyeoXbs2ANu3b6dNmzbcuXMHLy+vNNUdHh6Oi4sLYWFhODs7v/wCYTYbz93jRMATpnSoZNxXCmDWrit8v+dqlrShrIcjV4LjegPn96nJ0ygdPeoUhYf+8GtziApLyFx3eNxsK2vbLGmbEEKIlKX18ztXjdkJCwtDpVLh6uoKwNGjR3F1dTUGOgC+vr6o1WqOHz9O586dky0nOjqa6OiE9VjCw8Mt2m6RslH/LQ5Yq1g+OtUobEzPikBnbPOylPd0Mlm/p02V/wYiP74OP7xmesEnQWBtZ/F2CSGEMK9cs85OVFQUH330Eb169TJGb0FBQbi7u5vks7Kyws3NjaCglNdcmTZtGi4uLsYvb2/vFPOKrPEowsKLAb7g4uctGdWsDC0qeSbdHPTwXJhXM+G4UHX4KFACHSGEyKVyRc+OTqeje/fuKIrCggULMl3exIkTGTt2rPE4PDxcAp5XiL2NBnubhB/9GH1csFNUFQxTXEwzD9gKxV8YryOEECJXyfHBTnygc/PmTfbu3WvyTM7T05MHDx6Y5I+NjeXJkyd4enqmWKZWq0Wr1VqszSJnaFimAAevPkqS/kv/2ibHMTo9FVQ32aadaJpx6H7wqmHBFgohhMgKOfoxVnygc/XqVXbv3k3+/PlNzvv4+BAaGsqpU6eMaXv37sVgMFC3bt2sbq7IhDshz9lw9i5BZlpLp0phF37sWyvZc0Vc7U2Oz9DDNNDR2MCnDyTQEUKIPCJbe3YiIiK4du2a8TggIICzZ8/i5uZGoUKF6NatG6dPn2bz5s3o9XrjOBw3NzdsbGyoUKECrVq1YsiQISxcuBCdTsfIkSPp2bNnmmdiCcvZfTGY+fuv8V336pQo4GBy7tbjSO6HJayIvPhIIIuPgJuDDacnNc903W/VK2ryqCpZobdhTmXTiF9tDR/flw08hRAiD8nWnp2TJ09So0YNatSI+wt67Nix1KhRg8mTJ3P37l02btzInTt3qF69OoUKFTJ+HTlyxFjG8uXLKV++PM2aNaNNmzY0aNCAn376KbtuKc84cv0R7eYd5Nzt0AyX8fbSk5y+FcoHq88mOddoxj56/HQsSfqTZzEZri+xWMNLVlQ4vRS+r26aNvo8TH4kgY4QQuQx2fpbvUmTJqS2zE9algByc3NjxYoV5myWAHr/fByAt349zr9TWmaqrNBInfH7lX/f4uN1/6aaf+XftzJVH0DYc12y6eVVtyjyc0WICklIdC0Go86AWpPpeoUQQuQ88iesSNXTqFizljdhbeqBTlrzvEzICz1EagzMfu0prc9/jjoqMi6xYkdoNwfs3TJdnxBCiJwrRw9QFrnX8xh9wkEWbhvVrVYRbKzUvFWvGACj3iiNE5H45fuCjv8Mx8YQGTcA+Y1PodtiCXSEEOIVID07IlOWHbvJycAnfPdmNaw0CbHzv3cTtlhQkbZHkuYwo1tVvuxUGVvruEdS79ex550rc7F/5B+XoUp3aD8XbOxTKUUIIUReIsGOyJRJ688D0LScOzq9gRk7/Pm0XUXc7G2MeQwKlJi4NVP1aK3UKMBn7SvyybrzyebxreCBSqWKC3R0UfBNUTT6aOwBrO2h+zIo45updgghhMh95DGWSBe9QSFKp0+SHhIZw4d//sODp9GM+uMMB68m7FIe8OhZpuv1rejBhakt6VO3mEl6u6qFjN9/36t63DeKAptHg/6/LSjcSsFbf0mgI4QQryjp2RHp0mXBES7dD+f0pOasOnHbmK5/Yar3j343zFrvhFblsdYkjc2ndqiEjUZNjzrecevq3D4BOz+B23GzychXHN47BaosHDgkhBAiR5FgR7xU1wVHKOioZWHfWsZ1d45df8wXmy8a8+j0lhuT80Z5d7zdkh9jk99Ry6we1UEfC6v6wqWNCSdbfQP1hlusXUIIIXIHCXbES526GZIkTf/CgONvt1+2SN09anvzQYuyKWcwGMBvOuyfZpreeALUfccibRJCCJG7SLAj0izxjCrDy1YoNpNvu1VN8ZwaA6x9G87/lZBYoT10mAd2+bKgdUIIIXIDGaD8iktusHFKEnfmvNizkxGftq2QprQX+ZTMjxoDJx1GmwY6LadBj98l0BFCCGFCgp1X2IV7YZSftJ3JG5Kfyv2ixAHOiwOSM6JFRU+T42GNS/J2w5K4O2kBcLGzTnqRwcCiQn9xw/Yt3PSP4tIKVYfJT8Dn3Uy3SQghRN4jwc4rbO7uqwAsPXozTfkTBzgnA5OO40kPexsNRfObDjqe2DquV+fzjpWo5u3K6mE+LzRAB6v6YHsq0UavRevDwG2yr5UQQogUyZidV5g6ndOxIxNtAbHsWNoCpORUKezC7B7VAXi9dH4OX3uMlTqhLa0qF6JV5UKmF8VGw4aR4P/f4oTWDjBwC3jVyHA7hBBCvBok2HmFqdPZr1fry11mqff7XjUoUcABgLk9a/Dl5ovGvaySFXoL5lRJOG40HppMkN4cIYQQaSLBzitMlc6eHXNtb1XY1c74fQFHLXN6ptI78+ga/K9WwnG3RVC5i3kaIoQQ4pUgwc4rTJOFqwpvfq8B7s5abDRqbKzS0KUUHQFzKsPzRGODeq2Ecq0t10ghhBB5kgQ7r6D4gcbqFGKd/f4PzF5n5cIuacuoKHBtDyzvaprefxOUaGT2dgkhhMj7JNh5xRgMCq3n+qFRqynv6ZTk/P2w5wxYdCIbWgY8uAQb34M7iep39IR3DoFjwexpkxBCiFxPgp1XSFikjkhdLFeCIwC4dD88SZ57oVFZ3ay4fa12TYZjPySkFaoGTT+Fsi2yvj1CCCHyFAl2XhHLjgYyacMFBtQvnuz5KJ2eC/fCCI3UZW3DngbBd+VM07ovg4odsrYdQggh8iwJdl4RkzZcAGDxkcBkz4/64ww7LwZToZBz1jXq9gn41TfhuKgPvPUX2DhkXRuEEELkebKCch4Q9lyH3qCg0xs4fuMx0bFp3+8q3s6LwUDyj7YyQqNWUbJAKkHLrsmmgU7h2nErIUugI4QQwsykZyeXu/0kkobT91HN25WqhV1Yduwm3WoVYeab1bK1XY3KFODGo2dJTxyaDbunmKbJlHIhhBAWJD07udymf+4BcO52qHELhz9P3cnOJmFrrWZW9+rULBq3+7hxivuB6aaBjtoKPr4vgY4QQgiLkp6dPKrrgiPULeFG5xqFKeORdIq5JV3+Ii54mdK+EkXy2dG5nB3MKAPPEq3f024O1BoAWbiwoRBCiFeTBDt51KmbIZy6GcL8/dc5OL5pltWbeHVkFzsrPnDYAYsmJWRo9CE0mSj7WgkhhMgyEuzkYoGPnrHln/svzXf+bliGyrdSq4g1pLwh1l/D6+PlastXWy6x+b92GPtpru+DZZ1ML+j6K1TplqG2CCGEEBklY3ZysSYz93Ph3stnTy0/fivFrSFSY6VR0bBMgRTP1yqWj0Iudvyvd01jWhHVA/ijl2mg414RRp6SQEcIIUS2kGDnFXDo2iNS6aBJkVqlYumg10zSUtrE803NfgJte7NHMwr8tyaceG0YvHsUCpROfwOEEEIIM5DHWCJFapUK1csGEIffg9+7McP6gml600/ixufIAGQhhBDZTIIdkSIHbTKDiBP3EIXdgdmVTE4fVqry+uhlkK+4RdsmhBBCpJU8xhIpcra1TpJWxsMRW6L52Go5zK5sTF+vr0+5qMUM41MJdIQQQuQo0rOTS0REx2JnrUGTkZHGGVS1iKvJ8WdtytLt0Q84PVmUkOheEVp+xeifnwNgk2WtE0IIIdJGgp0c7vrDCBRFwXeWH/VKurFyqI/F6/zzHR/+On2XCa3KA+BbwZ1b/mcZuLd3Qia1NbSaBrUHg1oNbIlLlyE6QgghchgJdnKw7/dcZdauK8bjYzeecPpWCB7OthR2tTNLHZ1rFGbdmbvG45/71aZ2cTdqF3eLS3gaxM9Bb6KyCUm4qGwr6LYIbOyTlCexjhBCiJxGxuzkYIkDnXhd5h/h9W/2oigZmEv+gqkdKjGjW1V+6VfbmNasvHvcN4oCfjPgu3KonicKdDr+AL1XJQl02lfzAmBEU5liLoQQImeRnp0c6od911I9r9NnLtgJ/Kat8ftmFdxpWckDNwcb1GoVRD+F/9WBp4lWZ24zE14bkmJ5s7pX453GJalYyDlT7RJCCCHMTYKdHOhBeBQzdvinmud5jD7D5S95YaFAlUrFj33/6925vg+WvwkGXdyxS1HosQy8qqdaprVGTSUvlwy3SQghhLAUeYyVTW49juSPv2+h0xuSnAt7rnvp9b6zD6SrPgebhDVzGpZOZguIkEBY0SNum4f4QKdyNxh1+qWBjhBCCJGTSc9ONmk0Yx8AoZE6hjcpZUyP1RvYlIbNPR8+jU5XfYXz2dGqciGcba3iHlXFi4mEje/B+T8T0txKQs8/wL18uuoQQgghciIJdrLZ0RuPGd6kFIqicPTGY3r/fNwi9ThorRjbvKxp4p1TsKQ96J7FHaut4sbm1B5okTYIIYQQ2UGCnWxmMCjo9AbafX8I/+CnFqunR23vhIMnN2DTaAhI9Cis7XdQ522L1S+EEEJkFwl2stjpWyF4uSSskaM3KPxzJ8yigY6ttZru8cHOsQWwfYJphiH7oHBNi9UvhBBCZCcJdrLQhXthdJl/xCRNryjYaCw7TtynZH7UAfthzQCICk040fRTaDAGNPJjIIQQIu+STzkLuxf6nHeXn2bg68UJT2aW1d8BT2j/v0MWqfvnvrXYdOAY0/kalu1LOKGxgQ+vga1MFRdCCJH3SbBjQQaDQv1v9gLw/sqzfNW58kuuMJ/ahaxovq4azWOjEhK9akLTT6B0M1DJxg5CCCFeDRLsWNCjCNPp4WoLBhhze1angKOWxxHRlH24k7L/TIfEgU7r6VB3mMXqF0IIIXIqCXYsKOaFBQM1Fu5Ned35EewYAA8vJSQWqQO9V4O9m0XrFkIIIXIqCXYsKDrWNNgxR6zzRnl39l5+YJLmSCQN/PrAkzMJiRXaQ5vvwMkj85UKIYQQuZgEOxb04v5VmX2MNb1rVc7eCTUe57O3pujzS2zQToYn/yUWKAt914FLkUzVJYQQQuQVEuxY0HOdabCz6EhApstsV7UQK47fYo7NQtoXVaEJTLQwYLk20ON3UGtSLkAIIYR4xUiwY0EBj56ZHJ+/G565AlVQv1QB9rzlTqk//SAw4ZT+rQ1oSjfJXPlCCCFEHpStu577+fnRvn17vLy8UKlUrF+/3uS8oihMnjyZQoUKYWdnh6+vL1evXjXJ8+TJE/r06YOzszOurq4MHjyYiIiILLyLlI3/8x+zlhf/EKyUuxNUeRPKtIC31sJnoRLoCCGEECnI1mDn2bNnVKtWjR9++CHZ89OnT+f7779n4cKFHD9+HAcHB1q2bElUVMKU6j59+nDhwgV27drF5s2b8fPzY+jQoVl1CxbVtFxBk2NV/Jgf9/LQ9Rfos0bWzBFCCCFeIlsfY7Vu3ZrWrVsne05RFObMmcOnn35Kx44dAVi6dCkeHh6sX7+enj17cunSJbZv386JEyeoXbs2APPmzaNNmzbMnDkTLy+vLLsXcynj7sjyt+vy6+EAWlcuxD7/h8ZzEtIIIYQQ6ZetPTupCQgIICgoCF9fX2Oai4sLdevW5ejRowAcPXoUV1dXY6AD4Ovri1qt5vjx4ymWHR0dTXh4uMlXTuLubMvE1hUo5maf3U0RQgghcr0cG+wEBQUB4OFhuk6Mh4eH8VxQUBDu7u4m562srHBzczPmSc60adNwcXExfnl7e5u59XEqeTln6voXp6o3ryRr5gghhBDplWODHUuaOHEiYWFhxq/bt29bpJ6Fb9XK1PWqRO/O/nFNcLa1zmSLhBBCiFdPjg12PD09AQgODjZJDw4ONp7z9PTkwQPT1YRjY2N58uSJMU9ytFotzs7OJl+W4O1mT+A3bZn5ZrVMl2VtlWPfKiGEECJHy7GfoCVKlMDT05M9e/YY08LDwzl+/Dg+Pj4A+Pj4EBoayqlTp4x59u7di8FgoG7dulne5pR0q5X8asZ1iudLkta5ZmFLN0cIIYR4pWTrbKyIiAiuXbtmPA4ICODs2bO4ublRtGhRRo8ezZdffkmZMmUoUaIEkyZNwsvLi06dOgFQoUIFWrVqxZAhQ1i4cCE6nY6RI0fSs2fPXDETK7+D1vj9uc9acPZ2KK+Xym9MS7xxqLVa5mIJIYQQGZGtwc7Jkydp2rSp8Xjs2LEA9O/fn8WLFzN+/HiePXvG0KFDCQ0NpUGDBmzfvh1bW1vjNcuXL2fkyJE0a9YMtVpN165d+f7777P8XtKrZx1v7oclrBfkYmdN47Km6+o4aK14u0EJYvQG3J1tXyxCCCGEEGmgUhRFye5GZLfw8HBcXFwICwuz2Pid4hO2GL8f1qgkH7Qox2+HA/hm22VsrNRc+TL59YaEEEIIkby0fn7L3lhZrGIhZya2qQDAoNdL4GZvQ/3S+V9ylRBCCCEySoKdLGalSRh7Y2Olpnsdy6zxI4QQQog4OXY2Vl5VsoBDdjdBCCGEeKVIsJNFPmpVnpIFHfi4bYXsbooQQgjxSpEBymTNAGUhhBBCmFdaP7+lZ0cIIYQQeZoEO0IIIYTI0yTYEUIIIUSeJsGOEEIIIfI0CXaEEEIIkadJsCOEEEKIPE2CHSGEEELkaRLsCCGEECJPk2BHCCGEEHmaBDtCCCGEyNMk2BFCCCFEnibBjhBCCCHyNAl2hBBCCJGnSbAjhBBCiDzNKrsbkBMoigLEbRUvhBBCiNwh/nM7/nM8JRLsAE+fPgXA29s7m1sihBBCiPR6+vQpLi4uKZ5XKS8Lh14BBoOBe/fu4eTkhEqlMlu54eHheHt7c/v2bZydnc1Wbk6S1+9R7i/3y+v3mNfvD/L+Pcr9ZZyiKDx9+hQvLy/U6pRH5kjPDqBWqylSpIjFynd2ds6TP8CJ5fV7lPvL/fL6Peb1+4O8f49yfxmTWo9OPBmgLIQQQog8TYIdIYQQQuRpEuxYkFar5bPPPkOr1WZ3Uywmr9+j3F/ul9fvMa/fH+T9e5T7szwZoCyEEEKIPE16doQQQgiRp0mwI4QQQog8TYIdIYQQQuRpEuwIIYQQIk+TYMeCfvjhB4oXL46trS1169bl77//zu4mpcm0adOoU6cOTk5OuLu706lTJ/z9/U3yNGnSBJVKZfL1zjvvmOS5desWbdu2xd7eHnd3dz788ENiY2Oz8laSNWXKlCRtL1++vPF8VFQUI0aMIH/+/Dg6OtK1a1eCg4NNysip9wZQvHjxJPenUqkYMWIEkDvfOz8/P9q3b4+XlxcqlYr169ebnFcUhcmTJ1OoUCHs7Ozw9fXl6tWrJnmePHlCnz59cHZ2xtXVlcGDBxMREWGS559//qFhw4bY2tri7e3N9OnTLX1rQOr3p9Pp+Oijj6hSpQoODg54eXnRr18/7t27Z1JGcu/7N998Y5Inu+4PXv4eDhgwIEn7W7VqZZInt76HQLL/J1UqFTNmzDDmycnvYVo+F8z1u3P//v3UrFkTrVZL6dKlWbx4ceZvQBEWsXLlSsXGxkb57bfflAsXLihDhgxRXF1dleDg4Oxu2ku1bNlSWbRokXL+/Hnl7NmzSps2bZSiRYsqERERxjyNGzdWhgwZoty/f9/4FRYWZjwfGxurVK5cWfH19VXOnDmjbN26VSlQoIAyceLE7LglE5999plSqVIlk7Y/fPjQeP6dd95RvL29lT179ignT55U6tWrp9SvX994Piffm6IoyoMHD0zubdeuXQqg7Nu3T1GU3Pnebd26Vfnkk0+UtWvXKoCybt06k/PffPON4uLioqxfv145d+6c0qFDB6VEiRLK8+fPjXlatWqlVKtWTTl27Jhy8OBBpXTp0kqvXr2M58PCwhQPDw+lT58+yvnz55U//vhDsbOzU3788cdsvb/Q0FDF19dXWbVqlXL58mXl6NGjymuvvabUqlXLpIxixYopn3/+ucn7mvj/bHbe38vuUVEUpX///kqrVq1M2v/kyROTPLn1PVQUxeS+7t+/r/z222+KSqVSrl+/bsyTk9/DtHwumON3540bNxR7e3tl7NixysWLF5V58+YpGo1G2b59e6baL8GOhbz22mvKiBEjjMd6vV7x8vJSpk2blo2typgHDx4ogHLgwAFjWuPGjZX3338/xWu2bt2qqNVqJSgoyJi2YMECxdnZWYmOjrZkc1/qs88+U6pVq5bsudDQUMXa2lpZs2aNMe3SpUsKoBw9elRRlJx9b8l5//33lVKlSikGg0FRlNz93imKkuSDxGAwKJ6ensqMGTOMaaGhoYpWq1X++OMPRVEU5eLFiwqgnDhxwphn27ZtikqlUu7evasoiqLMnz9fyZcvn8k9fvTRR0q5cuUsfEemkvugfNHff/+tAMrNmzeNacWKFVNmz56d4jU55f4UJfl77N+/v9KxY8cUr8lr72HHjh2VN954wyQtN72HL34umOt35/jx45VKlSqZ1NWjRw+lZcuWmWqvPMaygJiYGE6dOoWvr68xTa1W4+vry9GjR7OxZRkTFhYGgJubm0n68uXLKVCgAJUrV2bixIlERkYazx09epQqVarg4eFhTGvZsiXh4eFcuHAhaxqeiqtXr+Ll5UXJkiXp06cPt27dAuDUqVPodDqT9658+fIULVrU+N7l9HtLLCYmht9//51BgwaZbHKbm9+7FwUEBBAUFGTynrm4uFC3bl2T98zV1ZXatWsb8/j6+qJWqzl+/LgxT6NGjbCxsTHmadmyJf7+/oSEhGTR3aRNWFgYKpUKV1dXk/RvvvmG/PnzU6NGDWbMmGHyeCA33N/+/ftxd3enXLlyDB8+nMePHxvP5aX3MDg4mC1btjB48OAk53LLe/ji54K5fncePXrUpIz4PJn97JSNQC3g0aNH6PV6kzcUwMPDg8uXL2dTqzLGYDAwevRoXn/9dSpXrmxM7927N8WKFcPLy4t//vmHjz76CP//t3enIVG1bRzA/2aOC2Mujc5MiaVlG2ip0DBREhnSEG1Ci4SV0EIr0UIUZdSHsi9GVEhEG/ShghYhqEgdKc0sy6mkmHIwI3AhY9KyyPR6PzzvzPucx+2ptJk57/8HA8f73HO8L64551wz59wzdjuuXbsGAGhsbOwxftc6TzKZTDh//jzGjx+PhoYGHDhwADNmzEBNTQ0aGxuh0Wi6nUT0er173N4c2z/duHEDTqcTq1atcrf5cu564hpTT2P+e86io6MV64cOHYrIyEhFn7i4uG7bcK2LiIgYlPH/rG/fvmHXrl3IyspS/Kjili1bkJKSgsjISDx48AC7d+9GQ0MD8vPzAXh/fHPmzEFmZibi4uLgcDiwZ88eWCwWVFRUwN/fX1U5vHDhAkJDQ5GZmalo95Uc9nReGKhjZ299Wltb8fXrVwQHB//SmFnsUJ82btyImpoalJWVKdrXrl3rXk5MTITRaER6ejocDgfGjBnzp4f5UywWi3s5KSkJJpMJo0aNwpUrV355R/JWZ86cgcViwYgRI9xtvpy7/3cdHR1YsmQJRAQFBQWKddu2bXMvJyUlQaPRYN26dTh8+LBP/AzBsmXL3MuJiYlISkrCmDFjUFpaivT0dA+ObOCdPXsWy5cvR1BQkKLdV3LY23nBm/Ey1iDQ6XTw9/fvdhd6U1MTDAaDh0b18zZt2oSbN2/CarUiJiamz74mkwkAUFtbCwAwGAw9xu9a503Cw8Mxbtw41NbWwmAw4Pv373A6nYo+f8+dr8RWX1+PoqIirF69us9+vpw74H9j6mt/MxgMaG5uVqz/8eMHPn786DN5dRU69fX1uHv3ruJTnZ6YTCb8+PEDb9++BeD98f1TfHw8dDqd4nXp6zkEgPv378Nut/e7XwLemcPezgsDdezsrc+wYcN+680oi51BoNFokJqaiuLiYndbV1cXiouLYTabPTiyf0dEsGnTJly/fh0lJSXdPjbtic1mAwAYjUYAgNlsxosXLxQHJ9cBetKkSYMy7l/1+fNnOBwOGI1GpKamIiAgQJE7u92Od+/euXPnK7GdO3cO0dHRmDt3bp/9fDl3ABAXFweDwaDIWWtrKyorKxU5czqdePLkibtPSUkJurq63MWe2WzGvXv30NHR4e5z9+5djB8/3uOXP1yFzps3b1BUVIThw4f3+xybzYYhQ4a4L/14c3w9ef/+PVpaWhSvS1/OocuZM2eQmpqKyZMn99vXm3LY33lhoI6dZrNZsQ1Xn98+d/7W7c3Uq0uXLklgYKCcP39eXr58KWvXrpXw8HDFXejeav369RIWFialpaWKKZDt7e0iIlJbWysHDx6Uqqoqqaurk8LCQomPj5e0tDT3NlxTDDMyMsRms8nt27clKirKK6Znb9++XUpLS6Wurk7Ky8tl9uzZotPppLm5WUT+mj4ZGxsrJSUlUlVVJWazWcxms/v53hybS2dnp8TGxsquXbsU7b6au7a2Nqmurpbq6moBIPn5+VJdXe2ejZSXlyfh4eFSWFgoz58/lwULFvQ49Tw5OVkqKyulrKxMEhISFNOWnU6n6PV6yc7OlpqaGrl06ZKEhIT8kWm9fcX3/ft3mT9/vsTExIjNZlPsk64ZLA8ePJCjR4+KzWYTh8MhFy9elKioKFmxYoVXxNdfjG1tbbJjxw6pqKiQuro6KSoqkpSUFElISJBv3765t+GrOXT59OmThISESEFBQbfne3sO+zsviAzMsdM19Xznzp3y6tUrOXnyJKeee7vjx49LbGysaDQamTp1qjx8+NDTQ/pXAPT4OHfunIiIvHv3TtLS0iQyMlICAwNl7NixsnPnTsV3tYiIvH37ViwWiwQHB4tOp5Pt27dLR0eHByJSWrp0qRiNRtFoNDJy5EhZunSp1NbWutd//fpVNmzYIBERERISEiKLFi2ShoYGxTa8NTaXO3fuCACx2+2Kdl/NndVq7fE1uXLlShH5a/r5vn37RK/XS2BgoKSnp3eLvaWlRbKyskSr1cqwYcMkJydH2traFH2ePXsm06dPl8DAQBk5cqTk5eV5PL66urpe90nXdyc9efJETCaThIWFSVBQkEycOFEOHTqkKBQ8GV9/Mba3t0tGRoZERUVJQECAjBo1StasWdPtzaGv5tDl1KlTEhwcLE6ns9vzvT2H/Z0XRAbu2Gm1WmXKlCmi0WgkPj5e8T9+ld9/gyAiIiJSJd6zQ0RERKrGYoeIiIhUjcUOERERqRqLHSIiIlI1FjtERESkaix2iIiISNVY7BAREZGqsdghIp+3atUqLFy40NPDICIvxV89JyKv5ufn1+f6/fv349ixY+D3oxJRb1jsEJFXa2hocC9fvnwZubm5sNvt7jatVgutVuuJoRGRj+BlLCLyagaDwf0ICwuDn5+fok2r1Xa7jDVz5kxs3rwZW7duRUREBPR6PU6fPo0vX74gJycHoaGhGDt2LG7duqX4XzU1NbBYLNBqtdDr9cjOzsaHDx/+cMRENNBY7BCRKl24cAE6nQ6PHj3C5s2bsX79eixevBjTpk3D06dPkZGRgezsbLS3twMAnE4nZs2aheTkZFRVVeH27dtoamrCkiVLPBwJEf0uFjtEpEqTJ0/G3r17kZCQgN27dyMoKAg6nQ5r1qxBQkICcnNz0dLSgufPnwMATpw4geTkZBw6dAgTJkxAcnIyzp49C6vVitevX3s4GiL6Hbxnh4hUKSkpyb3s7++P4cOHIzEx0d2m1+sBAM3NzQCAZ8+ewWq19nj/j8PhwLhx4wZ5xEQ0WFjsEJEqBQQEKP728/NTtLlmeXV1dQEAPn/+jHnz5uHIkSPdtmU0GgdxpEQ02FjsEBEBSElJwdWrVzF69GgMHcpDI5Ga8J4dIiIAGzduxMePH5GVlYXHjx/D4XDgzp07yMnJQWdnp6eHR0S/gcUOERGAESNGoLy8HJ2dncjIyEBiYiK2bt2K8PBwDBnCQyWRL/MTfu0oERERqRjfrhAREZGqsdghIiIiVWOxQ0RERKrGYoeIiIhUjcUOERERqRqLHSIiIlI1FjtERESkaix2iIiISNVY7BAREZGqsdghIiIiVWOxQ0RERKrGYoeIiIhU7T8osuSLGPAo5AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "# Prepare true values for comparison\n",
    "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot the predictions vs true values\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(true_values, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 3s/step - loss: 2.5174 \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3s/step - loss: 0.8724\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - loss: 0.3716\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - loss: 0.2340\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - loss: 0.1234\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - loss: 0.0654\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - loss: 0.0585\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - loss: 0.0436\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - loss: 0.0437\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3s/step - loss: 0.0354\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3s/step - loss: 0.0365\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - loss: 0.0322\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - loss: 0.0262\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - loss: 0.0308\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - loss: 0.0392 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0236 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0237 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0224 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0205 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0165 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 316ms/step - loss: 0.0149\n",
      "Test loss: 0.01493222638964653\n"
     ]
    }
   ],
   "source": [
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "dropoutn =  Dropout(0.5)(flatten)\n",
    "outputs = tf.keras.layers.Dense(1)(dropoutn) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 622ms/step - loss: 0.2029 \n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 617ms/step - loss: 0.0280 \n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 616ms/step - loss: 0.0172 \n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 615ms/step - loss: 0.0175 \n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 619ms/step - loss: 0.0095 \n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - loss: 0.0101 \n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0059 \n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - loss: 0.0056 \n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - loss: 0.0057 \n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 613ms/step - loss: 0.0067 \n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 605ms/step - loss: 0.0044 \n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 614ms/step - loss: 0.0051 \n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 618ms/step - loss: 0.0099 \n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 618ms/step - loss: 0.0062 \n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 617ms/step - loss: 0.0057 \n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 618ms/step - loss: 0.0051 \n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 618ms/step - loss: 0.0057 \n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - loss: 0.0070   \n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 2s/step - loss: 0.0045\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 2s/step - loss: 0.0044\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - loss: 0.0131   \n",
      "Test loss: 0.013140639290213585\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 5s/step - loss: 0.0052\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 5s/step - loss: 0.0027\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 5s/step - loss: 0.0015\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 5s/step - loss: 0.0013\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 5s/step - loss: 0.0011    \n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 5s/step - loss: 0.0011    \n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 5s/step - loss: 0.0014    \n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 5s/step - loss: 0.0012\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 5s/step - loss: 0.0014\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 5s/step - loss: 0.0021\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 5s/step - loss: 0.0018\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 5s/step - loss: 0.0012    \n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 4s/step - loss: 0.0014\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 5s/step - loss: 0.0014\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 5s/step - loss: 0.0013    \n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 5s/step - loss: 0.0020\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 5s/step - loss: 0.0013\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 5s/step - loss: 0.0014\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 4s/step - loss: 0.0016    \n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 5s/step - loss: 0.0016\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - loss: 0.0019    \n",
      "Test loss: 0.0018676120089367032\n"
     ]
    }
   ],
   "source": [
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss: {loss}')\n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 3s/step - loss: 0.2945\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 3s/step - loss: 0.4444\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3s/step - loss: 2.3743\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 3s/step - loss: 2.3743\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3s/step - loss: 2.3743\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 3s/step - loss: 2.3743\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - loss: 2.3743\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - loss: 2.3743\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - loss: 2.3743\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 2.3743 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 2.3743 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - loss: 2.3743 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 2.3743 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 2.3743 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 2.3743 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - loss: 2.3743 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - loss: 2.3743 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 319ms/step - loss: 2.3743\n",
      "Test loss: 2.3743340969085693\n"
     ]
    }
   ],
   "source": [
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
